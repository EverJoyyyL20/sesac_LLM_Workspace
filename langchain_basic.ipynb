{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ed0cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (1.2.6)\n",
      "Requirement already satisfied: openai in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (2.15.0)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (1.1.7)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (1.0.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain) (2.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (2.32.3)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (2.6.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain openai langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f9f8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-classic in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.5 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-classic) (1.2.7)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-classic) (1.1.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-classic) (0.6.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-classic) (2.10.3)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-classic) (6.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-classic) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-classic) (2.0.39)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-classic) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-classic) (24.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-classic) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-classic) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-classic) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.5->langchain-classic) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (2.6.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain-classic) (3.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86773ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1ï¸âƒ£ ìš´ì˜ì²´ì œ(OS) ê´€ë ¨ ê¸°ëŠ¥ ì‚¬ìš©\n",
    "# ================================\n",
    "import os\n",
    "\n",
    "# os ëª¨ë“ˆ:\n",
    "# - ìš´ì˜ì²´ì œ í™˜ê²½ë³€ìˆ˜ ì ‘ê·¼\n",
    "# - íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬\n",
    "# - ë””ë ‰í† ë¦¬ ì œì–´ ë“±\n",
    "# ì—¬ê¸°ì„œëŠ” \"í™˜ê²½ë³€ìˆ˜ì—ì„œ API KEY ê°€ì ¸ì˜¤ê¸°\" ìœ„í•´ ì‚¬ìš©\n",
    "\n",
    "# ================================\n",
    "# 2ï¸âƒ£ .env íŒŒì¼ ë¡œë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# ================================\n",
    "from dotenv import load_dotenv\n",
    "# python-dotenv ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# -> .env íŒŒì¼ ì•ˆì— ìˆëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼\n",
    "#    ìë™ìœ¼ë¡œ ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ë¡œ ë“±ë¡í•´ì¤Œ\n",
    "\n",
    "# ================================\n",
    "# 3ï¸âƒ£ .env íŒŒì¼ ì½ì–´ì„œ í™˜ê²½ë³€ìˆ˜ ì ìš©\n",
    "# ================================\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# í˜„ì¬ í”„ë¡œì íŠ¸ í´ë”ì˜ .env íŒŒì¼ì„ ì°¾ì•„ì„œ\n",
    "# ì•ˆì— ìˆëŠ” ê°’ë“¤ì„ í™˜ê²½ë³€ìˆ˜ë¡œ ë¡œë”©\n",
    "\n",
    "# ì˜ˆì‹œ (.env íŒŒì¼)\n",
    "# OPENAI_API_KEY=sk-xxxxxxxxxxxxx\n",
    "\n",
    "# ================================\n",
    "# 4ï¸âƒ£ í™˜ê²½ë³€ìˆ˜ì—ì„œ API KEY ê°€ì ¸ì˜¤ê¸°\n",
    "# ================================\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# os.getenv(\"í™˜ê²½ë³€ìˆ˜ì´ë¦„\")\n",
    "# â†’ ì‹œìŠ¤í…œì— ì €ì¥ëœ í™˜ê²½ë³€ìˆ˜ ê°’ì„ ê°€ì ¸ì˜´\n",
    "\n",
    "# ê²°ê³¼:\n",
    "# OPENAI_API_KEY ë³€ìˆ˜ì—ëŠ”\n",
    "# \"sk-xxxxxxxx\" ê°™ì€ ì‹¤ì œ OpenAI í‚¤ ë¬¸ìì—´ì´ ì €ì¥ë¨\n",
    "\n",
    "# â— ë³´ì•ˆ ì´ìœ :\n",
    "# ì½”ë“œì— í‚¤ë¥¼ ì§ì ‘ ì“°ë©´ ê¹ƒí—ˆë¸Œì— ìœ ì¶œë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ\n",
    "# .env + í™˜ê²½ë³€ìˆ˜ ë°©ì‹ ì‚¬ìš© (ì‹¤ë¬´ í‘œì¤€)\n",
    "\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 5ï¸âƒ£ LangChain OpenAI ì±„íŒ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4725ad",
   "metadata": {},
   "source": [
    "## Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554b6630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” OpenAIì—ì„œ ê°œë°œí•œ AI ì–¸ì–´ ëª¨ë¸, ChatGPTì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ ëŒ€í™”í•˜ê³  ì§ˆë¬¸ì— ë‹µë³€í•˜ë©° ê¸€ì“°ê¸°, ë²ˆì—­, í•™ìŠµ ë„ì›€ ë“± ì—¬ëŸ¬ ê°€ì§€ ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 14, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_376a7ccef1', 'id': 'chatcmpl-CzvJiilogmQlFPE11iqdzkw0I3mq8', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bd920-e72f-7230-a052-65cf0467f709-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 14, 'output_tokens': 68, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ChatOpenAI í´ë˜ìŠ¤\n",
    "# â†’ OpenAI Chat APIë¥¼ í¸í•˜ê²Œ ì“°ê²Œ í•´ì£¼ëŠ” ë˜í¼(wrapper)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 6ï¸âƒ£ LLM ê°ì²´ ìƒì„±\n",
    "# ================================\n",
    "llm=ChatOpenAI(model_name='gpt-4.1-mini',temperature=0)    \n",
    " # ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„  # ì°½ì˜ì„±(ëœë¤ì„±) ì¡°ì ˆ         \n",
    "\n",
    "\n",
    "# ğŸ”¹ model_name\n",
    "# 'gpt-4.1-mini'\n",
    "# â†’ ë¹ ë¥´ê³  ë¹„ìš© ì €ë ´í•œ ê²½ëŸ‰ GPT ëª¨ë¸\n",
    "\n",
    "# ğŸ”¹ temperature (0~2 ì‚¬ì´)\n",
    "# 0  : ê°€ì¥ ì•ˆì •ì , í•­ìƒ ë¹„ìŠ·í•œ ë‹µ\n",
    "# 0.7: ìì—°ìŠ¤ëŸ¬ì›€ + ì•½ê°„ ì°½ì˜ì„±\n",
    "# 1.5: ë§¤ìš° ì°½ì˜ì , ëœë¤ì„± í¼\n",
    "\n",
    "# ì§€ê¸ˆì€ temperature=0\n",
    "# â†’ \"í•­ìƒ ê°™ì€ ë‹µ ë‚˜ì˜¤ê²Œ\" ì„¤ì • (í…ŒìŠ¤íŠ¸/ìë™í™”ì— ì í•©)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 7ï¸âƒ£ ëª¨ë¸ì—ê²Œ ì§ˆë¬¸ ë³´ë‚´ê¸°\n",
    "# ================================\n",
    "result=llm.invoke(\"ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# invoke() í•¨ìˆ˜:\n",
    "# â†’ LLMì—ê²Œ í”„ë¡¬í”„íŠ¸(ì§ˆë¬¸)ë¥¼ ë³´ë‚´ê³ \n",
    "# â†’ AI ì‘ë‹µì„ ë°›ì•„ì˜¤ëŠ” í•¨ìˆ˜\n",
    "\n",
    "# ë‚´ë¶€ì ìœ¼ë¡œ ì¼ì–´ë‚˜ëŠ” ì¼:\n",
    "# 1. LangChainì´ OpenAI ì„œë²„ì— ìš”ì²­ ì „ì†¡\n",
    "# 2. GPT ëª¨ë¸ì´ ì‘ë‹µ ìƒì„±\n",
    "# 3. ì‘ë‹µì„ Python ê°ì²´ë¡œ ë°˜í™˜\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 8ï¸âƒ£ ê²°ê³¼ ì¶œë ¥\n",
    "# ================================\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "# result ëŠ” ë‹¨ìˆœ ë¬¸ìì—´ì´ ì•„ë‹˜\n",
    "\n",
    "# íƒ€ì…:\n",
    "# AIMessage ê°ì²´\n",
    "\n",
    "# ì•ˆì— í¬í•¨ëœ ì •ë³´:\n",
    "# - content : ì‹¤ì œ AI ë‹µë³€\n",
    "# - metadata : í† í° ì •ë³´ ë“±\n",
    "\n",
    "# ì‹¤ì œ ë‹µë³€ë§Œ ë³´ê³  ì‹¶ìœ¼ë©´:\n",
    "# print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e2fe1e",
   "metadata": {},
   "source": [
    "## Chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a5d3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤, ì¡´ ì”¨ë¼ê³  í•˜ì…¨ì–´ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 1ï¸âƒ£ LangChain OpenAI ì±„íŒ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ================================\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI:\n",
    "# OpenAIì˜ Chat APIë¥¼\n",
    "# LangChain ìŠ¤íƒ€ì¼ë¡œ ì‰½ê²Œ ì“°ê²Œ í•´ì£¼ëŠ” í´ë˜ìŠ¤\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 2ï¸âƒ£ ë©”ì‹œì§€ íƒ€ì… í´ë˜ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ================================\n",
    "from langchain_classic.schema import AIMessage,HumanMessage,SystemMessage\n",
    "\n",
    "\n",
    "# LangChain ë©”ì‹œì§€ êµ¬ì¡°ëŠ” 3ê°€ì§€ ê¸°ë³¸ ì—­í• (role)ì„ ì‚¬ìš©í•¨\n",
    "\n",
    "# ğŸ”¹ SystemMessage\n",
    "# - AIì˜ ì„±ê²©, ê·œì¹™, ì—­í•  ì„¤ì •\n",
    "# - \"ë„ˆëŠ” ì¹œì ˆí•œ ë¹„ì„œì•¼\" ê°™ì€ ì§€ì‹œ\n",
    "\n",
    "# ğŸ”¹ HumanMessage\n",
    "# - ì‚¬ìš©ì ë©”ì‹œì§€\n",
    "# - ì‚¬ëŒì´ ì…ë ¥í•œ ë§\n",
    "\n",
    "# ğŸ”¹ AIMessage\n",
    "# - AIê°€ ì´ì „ì— ëŒ€ë‹µí•œ ë‚´ìš©\n",
    "# - ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¬í˜„ìš©\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 3ï¸âƒ£ ChatGPT ëª¨ë¸ ê°ì²´ ìƒì„±\n",
    "# ================================\n",
    "chat=ChatOpenAI(model_name=\"gpt-4.1-mini\",# ì‚¬ìš©í•  GPT ëª¨ë¸\n",
    "                temperature=0)     # ì¶œë ¥ ëœë¤ì„± ì œì–´\n",
    "\n",
    "\n",
    "# model_name:\n",
    "# gpt-4.1-mini = ë¹ ë¥´ê³  ì €ë ´í•œ ìµœì‹  ê²½ëŸ‰ ëª¨ë¸\n",
    "\n",
    "# temperature=0:\n",
    "# â†’ ê°€ì¥ ì•ˆì •ì ì¸ ë‹µë³€\n",
    "# â†’ ë§¤ë²ˆ ê±°ì˜ ê°™ì€ ê²°ê³¼ ì¶œë ¥\n",
    "# â†’ í…ŒìŠ¤íŠ¸ / ìë™í™”ì— ì í•©\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 4ï¸âƒ£ ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "# ================================\n",
    "\n",
    "messages=[\n",
    "    # ------------------------\n",
    "    # ì‹œìŠ¤í…œ ì—­í•  ì„¤ì •\n",
    "    # ------------------------\n",
    "    SystemMessage(content=\"You are a helpful assistant\"),\n",
    "\n",
    "    # AIì—ê²Œ ì—­í•  ë¶€ì—¬\n",
    "    # â†’ \"ë„ˆëŠ” ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤\"\n",
    "\n",
    "\n",
    "    # ------------------------\n",
    "    # ì²« ë²ˆì§¸ ì‚¬ìš©ì ì…ë ¥\n",
    "    # ------------------------\n",
    "    HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì¡´ì´ë¼ê³  í•©ë‹ˆë‹¤!'),\n",
    "     # ì‚¬ìš©ìê°€ ìê¸° ì´ë¦„ì„ \"ì¡´\"ì´ë¼ê³  ì•Œë ¤ì¤Œ\n",
    "\n",
    "    # ------------------------\n",
    "    # AIê°€ ì´ì „ì— í–ˆë˜ ëŒ€ë‹µ\n",
    "    # ------------------------\n",
    "    AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì¡´ ì”¨! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?'),\n",
    "    # AIê°€ \"ì¡´\"ì´ë¼ëŠ” ì´ë¦„ì„ ì¸ì‹í•´ì„œ ì‘ë‹µí•œ ìƒí™©ì„ ì €ì¥\n",
    "\n",
    "    # ------------------------\n",
    "    # ë‘ ë²ˆì§¸ ì‚¬ìš©ì ì§ˆë¬¸\n",
    "    # ------------------------\n",
    "    HumanMessage(content=\"ì œ ì´ë¦„ì„ ì•„ì„¸ìš”?\")\n",
    "        # ì‚¬ìš©ìê°€:\n",
    "    # \"ë‚´ ì´ë¦„ ê¸°ì–µí•´?\"\n",
    "]\n",
    "\n",
    "# ğŸ‘‰ ì´ messages ë¦¬ìŠ¤íŠ¸ ìì²´ê°€\n",
    "# \"ëŒ€í™” ê¸°ë¡\" ì—­í• ì„ í•¨\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 5ï¸âƒ£ GPT ëª¨ë¸ì—ê²Œ ì „ì²´ ëŒ€í™” ì „ë‹¬\n",
    "# ================================\n",
    "result=chat.invoke(messages)\n",
    "\n",
    "\n",
    "# invoke() í•¨ìˆ˜:\n",
    "# â†’ messages ì „ì²´ë¥¼ GPT ì„œë²„ë¡œ ì „ì†¡\n",
    "# â†’ ëª¨ë¸ì´ ëŒ€í™” ë§¥ë½(context)ì„ ë³´ê³  ë‹µë³€ ìƒì„±\n",
    "\n",
    "# ì‹¤ì œ ë‚´ë¶€ ì „ë‹¬ êµ¬ì¡° (ê°œë…):\n",
    "\n",
    "# System: You are a helpful assistant\n",
    "# User: ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì¡´ì´ë¼ê³  í•©ë‹ˆë‹¤!\n",
    "# Assistant: ì•ˆë…•í•˜ì„¸ìš”, ì¡´ ì”¨! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
    "# User: ì œ ì´ë¦„ì„ ì•„ì„¸ìš”?\n",
    "\n",
    "# GPTëŠ” ì´ íë¦„ì„ ë³´ê³ \n",
    "# \"ì•„ ì´ë¦„ì€ ì¡´ì´êµ¬ë‚˜\" í•˜ê³  ë‹µë³€ ìƒì„±\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 6ï¸âƒ£ AI ì‘ë‹µ ì¶œë ¥\n",
    "# ================================\n",
    "print(result.content)\n",
    "\n",
    "\n",
    "# result íƒ€ì…:\n",
    "# AIMessage ê°ì²´\n",
    "\n",
    "# result.content:\n",
    "# ì‹¤ì œ GPTê°€ ìƒì„±í•œ í…ìŠ¤íŠ¸ ë‚´ìš©ë§Œ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc7f9f",
   "metadata": {},
   "source": [
    "## Callbackì„ ì´ìš©í•œ ìŠ¤íŠ¸ë¦¬ë°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a66b716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” OpenAIì—ì„œ ê°œë°œí•œ AI ì–¸ì–´ ëª¨ë¸, ChatGPTì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ ëŒ€í™”í•˜ê³  ì§ˆë¬¸ì— ë‹µë³€í•˜ë©° ê¸€ì“°ê¸°, ë²ˆì—­, í•™ìŠµ ë„ì›€ ë“± ì—¬ëŸ¬ ê°€ì§€ ì‘ì—…ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 1ï¸âƒ£ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ì½œë°± í•¸ë“¤ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ================================\n",
    "from langchain_classic.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# StreamingStdOutCallbackHandler ì—­í• :\n",
    "# GPTê°€ ìƒì„±í•˜ëŠ” í† í°(token)ì„\n",
    "# \"ìƒì„±ë˜ëŠ” ì¦‰ì‹œ\" ì½˜ì†”(stdout)ì— ì¶œë ¥\n",
    "\n",
    "# ì¦‰:\n",
    "# GPT â†’ í† í° ìƒì„± â†’ ë°”ë¡œ print\n",
    "# ChatGPT ì›¹ í™”ë©´ì²˜ëŸ¼ ê¸€ì íƒ€ì´í•‘ íš¨ê³¼ êµ¬í˜„\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 2ï¸âƒ£ OpenAI ì±„íŒ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ================================\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI:\n",
    "# OpenAI Chat APIë¥¼ LangChain ì¸í„°í˜ì´ìŠ¤ë¡œ ê°ì‹¸ë†“ì€ í´ë˜ìŠ¤\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 3ï¸âƒ£ ë©”ì‹œì§€ íƒ€ì… ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ================================\n",
    "from langchain_classic.schema import HumanMessage\n",
    "\n",
    "\n",
    "# HumanMessage:\n",
    "# \"ì‚¬ìš©ì ì—­í• (user)\" ë©”ì‹œì§€ ê°ì²´\n",
    "# GPTì—ê²Œ ì „ë‹¬í•  ì§ˆë¬¸ ì…ë ¥ìš©\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 4ï¸âƒ£ ChatGPT ëª¨ë¸ ê°ì²´ ìƒì„±\n",
    "# ================================\n",
    "chat=ChatOpenAI(\n",
    "    model_name='gpt-4.1-mini',\n",
    "    # ì‚¬ìš©í•  GPT ëª¨ë¸\n",
    "    # ë¹ ë¥´ê³  ë¹„ìš© íš¨ìœ¨ì ì¸ mini ëª¨ë¸\n",
    "    temperature=0,\n",
    "    # ì¶œë ¥ ëœë¤ì„± ì œì–´\n",
    "    # 0 = ê°€ì¥ ì•ˆì •ì , í•­ìƒ ë¹„ìŠ·í•œ ë‹µë³€\n",
    "    streaming=True,\n",
    "    # â­ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ í™œì„±í™”\n",
    "    # GPTê°€ ë‹µë³€ì„ \"í•œ ë²ˆì—\" ì£¼ëŠ” ê²ƒì´ ì•„ë‹ˆë¼\n",
    "    # í† í° ë‹¨ìœ„ë¡œ ìˆœì°¨ ìƒì„±\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "     # ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•  ì½œë°± ë“±ë¡\n",
    "\n",
    "    # StreamingStdOutCallbackHandler:\n",
    "    # â†’ í† í°ì´ ìƒì„±ë  ë•Œë§ˆë‹¤\n",
    "    # â†’ ìë™ìœ¼ë¡œ ì½˜ì†”ì— ì¶œë ¥\n",
    "\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 5ï¸âƒ£ ì‚¬ìš©ì ë©”ì‹œì§€ ìƒì„±\n",
    "# ================================\n",
    "\n",
    "# HumanMessage:\n",
    "# role = user\n",
    "# content = ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë¬¸ì¥\n",
    "\n",
    "# messages ë¦¬ìŠ¤íŠ¸:\n",
    "# â†’ GPTì—ê²Œ ë³´ë‚¼ ëŒ€í™” ë¬¶ìŒ\n",
    "messages=[HumanMessage(content=\"ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”\")]\n",
    "\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 6ï¸âƒ£ GPTì—ê²Œ ìš”ì²­ ì „ì†¡\n",
    "# ================================\n",
    "result=chat.invoke(messages)\n",
    "\n",
    "# invoke() ì‹¤í–‰ ì‹œ:\n",
    "\n",
    "# 1. GPT ì„œë²„ì— ìš”ì²­ ì „ì†¡\n",
    "# 2. GPTê°€ í† í° ë‹¨ìœ„ë¡œ ì‘ë‹µ ìƒì„±\n",
    "# 3. ìƒì„±ë  ë•Œë§ˆë‹¤ callback ì‹¤í–‰\n",
    "# 4. StreamingStdOutCallbackHandlerê°€\n",
    "#    ì‹¤ì‹œê°„ ì½˜ì†” ì¶œë ¥ ìˆ˜í–‰\n",
    "\n",
    "# â— streaming ëª¨ë“œì—ì„œëŠ”\n",
    "# ì´ë¯¸ í™”ë©´ì— ì¶œë ¥ë˜ê¸° ë•Œë¬¸ì—\n",
    "# resultë¥¼ ë”°ë¡œ printí•˜ì§€ ì•Šì•„ë„ ë¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb28b90",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "\n",
    "**Prompt templates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e9e0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ë‹¤ìŒ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "ìš”ë¦¬: ì¹´ë ˆ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ì•ˆì— ìˆëŠ” PromptTemplate í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤\n",
    "# PromptTemplateëŠ” \"í”„ë¡¬í”„íŠ¸(ì§ˆë¬¸) í…œí”Œë¦¿\"ì„ ë§Œë“¤ê¸° ìœ„í•œ ë„êµ¬ì´ë‹¤\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "\n",
    "# LLMì—ê²Œ ë³´ë‚¼ ê¸°ë³¸ ì§ˆë¬¸ í…œí”Œë¦¿ì„ ë¬¸ìì—´ë¡œ ë§Œë“ ë‹¤\n",
    "# \"\"\" \"\"\" ëŠ” ì—¬ëŸ¬ ì¤„ ë¬¸ìì—´(ë©€í‹°ë¼ì¸ ë¬¸ìì—´)ì„ ë§Œë“¤ ë•Œ ì‚¬ìš©í•œë‹¤\n",
    "template=\"\"\"\n",
    "ë‹¤ìŒ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "ìš”ë¦¬: {dish}\n",
    "\"\"\"\n",
    "\n",
    "# PromptTemplate ê°ì²´ë¥¼ ìƒì„±í•œë‹¤\n",
    "# ì¦‰, ìœ„ì—ì„œ ë§Œë“  templateì„ \"í”„ë¡¬í”„íŠ¸ í‹€\"ë¡œ ë“±ë¡í•˜ëŠ” ì‘ì—…ì´ë‹¤\n",
    "prompt=PromptTemplate(\n",
    "    # input_variablesëŠ” í…œí”Œë¦¿ ì•ˆì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜ ì´ë¦„ ëª©ë¡ì´ë‹¤\n",
    "    # ì—¬ê¸°ì„œëŠ” {dish} í•˜ë‚˜ë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ì— 'dish'ë§Œ ë„£ëŠ”ë‹¤\n",
    "    # LangChainì´ ë³€ìˆ˜ ì´ë¦„ì´ ë§ëŠ”ì§€ ìë™ìœ¼ë¡œ ê²€ì‚¬í•´ì¤€ë‹¤\n",
    "    input_variables=['dish'],\n",
    "\n",
    "    # ì‹¤ì œ ì‚¬ìš©í•  í…ìŠ¤íŠ¸ í…œí”Œë¦¿ì„ ì§€ì •í•œë‹¤\n",
    "    # ìœ„ì—ì„œ ë§Œë“  template ë¬¸ìì—´ì„ ë„£ì–´ì¤€ë‹¤\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# prompt.format()ì€ í…œí”Œë¦¿ì— ì‹¤ì œ ê°’ì„ ì±„ì›Œ ë„£ëŠ” í•¨ìˆ˜ì´ë‹¤\n",
    "# dish='ì¹´ë ˆ' ë¼ê³  ì „ë‹¬í•˜ë©´\n",
    "# í…œí”Œë¦¿ ì•ˆì˜ {dish} ìë¦¬ì— \"ì¹´ë ˆ\"ê°€ ë“¤ì–´ê°„ë‹¤\n",
    "result=prompt.format(dish='ì¹´ë ˆ')\n",
    "\n",
    "# ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ì¥ì„ ì½˜ì†”ì— ì¶œë ¥í•œë‹¤\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f4452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ë‹¹ì‹ ì€ ì˜êµ­ ìš”ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ë‹¤ìŒ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ ì£¼ì„¸ìš”. \\n\\nìš”ë¦¬:ê³ ê¸°ê°ìì¡°ë¦¼', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# LangChainì—ì„œ í”„ë¡¬í”„íŠ¸(ì§ˆë¬¸ í…œí”Œë¦¿) ê´€ë ¨ í´ë˜ìŠ¤ë“¤ì„ ë¶ˆëŸ¬ì˜¨ë‹¤\n",
    "from langchain_classic.prompts import (\n",
    "     # ì—¬ëŸ¬ ê°œì˜ ë©”ì‹œì§€(System + Human)ë¥¼ í•˜ë‚˜ì˜ ì±„íŒ… í”„ë¡¬í”„íŠ¸ë¡œ ë¬¶ì–´ì£¼ëŠ” í´ë˜ìŠ¤\n",
    "    ChatPromptTemplate,\n",
    "    # ì¼ë°˜ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ìš© í…œí”Œë¦¿ í´ë˜ìŠ¤ (ì´ë²ˆ ì½”ë“œì—ì„œëŠ” ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)\n",
    "    PromptTemplate,\n",
    "    # System ì—­í• (ì±—ë´‡ ì„±ê²©, ê·œì¹™, ì—­í•  ì„¤ì •)ì„ ìœ„í•œ ë©”ì‹œì§€ í…œí”Œë¦¿ í´ë˜ìŠ¤\n",
    "    SystemMessagePromptTemplate,\n",
    "     # Human ì—­í• (ì‚¬ìš©ì ì§ˆë¬¸)ì„ ìœ„í•œ ë©”ì‹œì§€ í…œí”Œë¦¿ í´ë˜ìŠ¤\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# ì‹¤ì œ ChatGPT APIì— ì „ë‹¬ë˜ëŠ” ë©”ì‹œì§€ íƒ€ì… í´ë˜ìŠ¤ë“¤ì„ ë¶ˆëŸ¬ì˜¨ë‹¤\n",
    "from langchain_classic.schema import HumanMessage,SystemMessage\n",
    "\n",
    "# ì—¬ëŸ¬ ê°œì˜ ë©”ì‹œì§€ í…œí”Œë¦¿ì„ ë¬¶ì–´ì„œ \"ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\"ì„ ìƒì„±í•œë‹¤\n",
    "chat_prompt=ChatPromptTemplate.from_messages([\n",
    "    # System ë©”ì‹œì§€ í…œí”Œë¦¿ ìƒì„±\n",
    "    # {country} ëŠ” ë‚˜ì¤‘ì— ì‹¤ì œ êµ­ê°€ëª…ì´ ë“¤ì–´ê°ˆ ìë¦¬(ë³€ìˆ˜)\n",
    "    SystemMessagePromptTemplate.from_template(\"ë‹¹ì‹ ì€ {country} ìš”ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"),\n",
    "     # Human(ì‚¬ìš©ì) ë©”ì‹œì§€ í…œí”Œë¦¿ ìƒì„±\n",
    "    # \\n\\n ì€ ì¤„ë°”ê¿ˆ(ê°€ë…ì„±ì„ ìœ„í•´ ë¬¸ë‹¨ ë¶„ë¦¬)\n",
    "    # {dish} ëŠ” ë‚˜ì¤‘ì— ì‹¤ì œ ìš”ë¦¬ ì´ë¦„ì´ ë“¤ì–´ê°ˆ ìë¦¬\n",
    "    HumanMessagePromptTemplate.from_template(\"ë‹¤ìŒ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ ì£¼ì„¸ìš”. \\n\\nìš”ë¦¬:{dish}\")\n",
    "])\n",
    "\n",
    "# format_prompt()ëŠ” í…œí”Œë¦¿ì— ì‹¤ì œ ê°’ì„ ì±„ì›Œ ë„£ëŠ” í•¨ìˆ˜ì´ë‹¤\n",
    "# country -> \"ì˜êµ­\"\n",
    "# dish -> \"ê³ ê¸°ê°ìì¡°ë¦¼\"\n",
    "# to_messages()ëŠ” LangChain ë©”ì‹œì§€ ê°ì²´(SystemMessage, HumanMessage) í˜•íƒœë¡œ ë³€í™˜í•œë‹¤\n",
    "messages=chat_prompt.format_prompt(country=\"ì˜êµ­\",dish=\"ê³ ê¸°ê°ìì¡°ë¦¼\").to_messages()\n",
    "\n",
    "# ìµœì¢… ìƒì„±ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•œë‹¤\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082b4f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê³ ê¸°ê°ìì¡°ë¦¼ì€ ë¶€ë“œëŸ¬ìš´ ê°ìì™€ ê³ ê¸°ê°€ ì–´ìš°ëŸ¬ì ¸ ê¹Šì€ ë§›ì„ ë‚´ëŠ” í•œêµ­ì‹ ê°€ì • ìš”ë¦¬ì…ë‹ˆë‹¤. ì˜êµ­ì‹ ìŠ¤íƒ€ì¼ë¡œ ì•½ê°„ ë³€í˜•í•˜ì—¬ í’ë¯¸ë¥¼ ë”í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ê³ ê¸°ê°ìì¡°ë¦¼ (British-style Braised Beef and Potatoes)\n",
      "\n",
      "#### ì¬ë£Œ (4ì¸ë¶„)\n",
      "- ì†Œê³ ê¸° (ì°œìš© ë˜ëŠ” ë¶ˆê³ ê¸°ìš©) 400g\n",
      "- ê°ì 4ê°œ (ì¤‘ê°„ í¬ê¸°, ê¹ë‘‘ì°ê¸°)\n",
      "- ì–‘íŒŒ 1ê°œ (êµµê²Œ ì±„ì°ê¸°)\n",
      "- ë§ˆëŠ˜ 3ìª½ (ë‹¤ì§„ ê²ƒ)\n",
      "- ë‹¹ê·¼ 1ê°œ (ì„ íƒì‚¬í•­, ê¹ë‘‘ì°ê¸°)\n",
      "- ì˜¬ë¦¬ë¸Œ ì˜¤ì¼ 2í°ìˆ \n",
      "- ì†Œê¸ˆ, í›„ì¶” ì•½ê°„\n",
      "- ìš°ìŠ¤í„° ì†ŒìŠ¤ 2í°ìˆ \n",
      "- ê°„ì¥ 3í°ìˆ \n",
      "- ì„¤íƒ• 1í°ìˆ \n",
      "- í† ë§ˆí†  í˜ì´ìŠ¤íŠ¸ 1í°ìˆ \n",
      "- ì†Œê³ ê¸° ìœ¡ìˆ˜ ë˜ëŠ” ë¬¼ 300ml\n",
      "- ì›”ê³„ìˆ˜ì 1ì¥\n",
      "- íƒ€ì„ (ë§ë¦° ê²ƒ) 1ì‘ì€ìˆ \n",
      "- íŒŒìŠ¬ë¦¬ (ë‹¤ì§„ ê²ƒ, ë§ˆë¬´ë¦¬ìš©)\n",
      "\n",
      "#### ì¡°ë¦¬ ë°©ë²•\n",
      "1. **ì¬ë£Œ ì¤€ë¹„**  \n",
      "   ì†Œê³ ê¸°ëŠ” í•œ ì… í¬ê¸°ë¡œ ì°ê³ , ê°ìëŠ” ê»ì§ˆì„ ë²—ê¸°ê³  í¼ì§í•˜ê²Œ ê¹ë‘‘ì°ê¸° í•©ë‹ˆë‹¤. ì–‘íŒŒì™€ ë‹¹ê·¼ë„ ì¤€ë¹„í•´ ë‘¡ë‹ˆë‹¤.\n",
      "\n",
      "2. **ê³ ê¸° ë³¶ê¸°**  \n",
      "   í° íŒ¬ì´ë‚˜ ëƒ„ë¹„ì— ì˜¬ë¦¬ë¸Œ ì˜¤ì¼ì„ ë‘ë¥´ê³  ì¤‘ê°„ ë¶ˆì—ì„œ ë‹¤ì§„ ë§ˆëŠ˜ê³¼ ì–‘íŒŒë¥¼ ë„£ì–´ í–¥ì´ ì˜¬ë¼ì˜¬ ë•Œê¹Œì§€ ë³¶ìŠµë‹ˆë‹¤.  \n",
      "   ì†Œê³ ê¸°ë¥¼ ë„£ê³  ê²‰ë©´ì´ ê°ˆìƒ‰ì´ ë  ë•Œê¹Œì§€ ë³¶ì•„ì¤ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì–‘ë… ë„£ê¸°**  \n",
      "   ìš°ìŠ¤í„° ì†ŒìŠ¤, ê°„ì¥, ì„¤íƒ•, í† ë§ˆí†  í˜ì´ìŠ¤íŠ¸ë¥¼ ë„£ê³  ì˜ ì„ì–´ ê³ ê¸°ì— ì–‘ë…ì´ ë°°ë„ë¡ ë³¶ì•„ì¤ë‹ˆë‹¤.\n",
      "\n",
      "4. **ê°ìì™€ ìœ¡ìˆ˜ ë„£ê¸°**  \n",
      "   ê°ìì™€ ë‹¹ê·¼ì„ ë„£ê³  ê³ ê¸°ì™€ ì˜ ì„ì€ ë’¤, ì†Œê³ ê¸° ìœ¡ìˆ˜ ë˜ëŠ” ë¬¼ì„ ë¶€ì–´ì¤ë‹ˆë‹¤. ì›”ê³„ìˆ˜ìê³¼ íƒ€ì„ë„ ë„£ì–´ í–¥ì„ ë”í•©ë‹ˆë‹¤.\n",
      "\n",
      "5. **ì¡°ë¦¼**  \n",
      "   ëšœê»‘ì„ ë®ê³  ì¤‘ì•½ë¶ˆì—ì„œ 30~40ë¶„ ì •ë„ ê°ìê°€ ë¶€ë“œëŸ¬ì›Œì§ˆ ë•Œê¹Œì§€ ì¡°ë¦½ë‹ˆë‹¤. ì¤‘ê°„ì¤‘ê°„ êµ­ë¬¼ì´ ë„ˆë¬´ ì¡¸ì•„ë“¤ë©´ ë¬¼ì„ ì¡°ê¸ˆì”© ì¶”ê°€í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "6. **ë§ˆë¬´ë¦¬**  \n",
      "   ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„ ë§ì¶”ê³ , ë¶ˆì„ ëˆ í›„ ë‹¤ì§„ íŒŒìŠ¬ë¦¬ë¥¼ ë¿Œë ¤ì„œ í–¥ê¸‹í•¨ì„ ë”í•©ë‹ˆë‹¤.\n",
      "\n",
      "#### ì„œë¹™ íŒ\n",
      "- ë”°ëœ»í•œ ë°¥ê³¼ í•¨ê»˜ ë‚´ê±°ë‚˜, êµ¬ìš´ ë¹µê³¼ ê³ë“¤ì—¬ë„ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "- ì‹ ì„ í•œ ìƒëŸ¬ë“œì™€ í•¨ê»˜ ë‚´ë©´ ê· í˜• ì¡íŒ í•œ ë¼ê°€ ë©ë‹ˆë‹¤.\n",
      "\n",
      "ì˜êµ­ì‹ í—ˆë¸Œì™€ ìš°ìŠ¤í„° ì†ŒìŠ¤ê°€ ë“¤ì–´ê°€ ê°ì¹ ë§›ì´ í’ë¶€í•œ ê³ ê¸°ê°ìì¡°ë¦¼ì…ë‹ˆë‹¤. ë§›ìˆê²Œ ì¦ê¸°ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# LangChainì—ì„œ OpenAI ì±„íŒ… ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ChatOpenAI í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI ê°ì²´ ìƒì„± (ì¦‰, GPT ëª¨ë¸ê³¼ ì—°ê²°í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ ìƒì„±)\n",
    "\n",
    "# ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„ ì§€ì •\n",
    "# 'gpt-4.1-mini' ëŠ” ë¹ ë¥´ê³  ë¹„ìš©ì´ ì €ë ´í•œ ê²½ëŸ‰ ëª¨ë¸\n",
    "# temperatureëŠ” ì‘ë‹µì˜ \"ëœë¤ì„±(ì°½ì˜ì„±)\" ì¡°ì ˆ ê°’\n",
    "# 0ì´ë©´ ê°€ì¥ ì•ˆì •ì ì´ê³  í•­ìƒ ë¹„ìŠ·í•œ ë‹µë³€ì„ ìƒì„±\n",
    "chat=ChatOpenAI(model_name='gpt-4.1-mini',temperature=0)\n",
    "\n",
    "# invoke()ëŠ” ì‹¤ì œë¡œ ëª¨ë¸ì—ê²Œ ìš”ì²­ì„ ë³´ë‚´ëŠ” í•¨ìˆ˜ì´ë‹¤\n",
    "# messagesëŠ” ì´ì „ ì½”ë“œì—ì„œ ë§Œë“  SystemMessage + HumanMessage ëª©ë¡\n",
    "# ì´ ì¤„ì—ì„œ ì¸í„°ë„·ì„ í†µí•´ OpenAI ì„œë²„ì— ìš”ì²­ì´ ì „ì†¡ëœë‹¤\n",
    "result=chat.invoke(messages)\n",
    "# result.content ëŠ” ëª¨ë¸ì´ ìƒì„±í•œ \"í…ìŠ¤íŠ¸ ì‘ë‹µ ë‚´ìš©\"ë§Œ êº¼ë‚´ëŠ” ë¶€ë¶„\n",
    "# print()ë¡œ ì½˜ì†”ì— ì¶œë ¥í•œë‹¤\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7fc9c7",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "**PydanticOutputParser**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "995e52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pydantic ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ BaseModelê³¼ Fieldë¥¼ ê°€ì ¸ì˜¨ë‹¤\n",
    "# BaseModel : ë°ì´í„° êµ¬ì¡°ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ê¸°ë³¸ í´ë˜ìŠ¤\n",
    "# Field     : ê° ë³€ìˆ˜(í•„ë“œ)ì— ì„¤ëª…, ê¸°ë³¸ê°’, ì¡°ê±´ ë“±ì„ ì¶”ê°€í•  ë•Œ ì‚¬ìš©\n",
    "from pydantic import BaseModel,Field\n",
    "\n",
    "\n",
    "# Recipeë¼ëŠ” ì´ë¦„ì˜ ë°ì´í„° ëª¨ë¸(ì„¤ê³„ë„)ì„ ë§Œë“ ë‹¤\n",
    "# BaseModelì„ ìƒì†í•˜ë©´ ìë™ìœ¼ë¡œ ë°ì´í„° ê²€ì¦ ê¸°ëŠ¥ì´ ìƒê¸´ë‹¤\n",
    "class Recipe(BaseModel):\n",
    "\n",
    "    # ingredientsë¼ëŠ” ë³€ìˆ˜(í•„ë“œ)ë¥¼ ì •ì˜\n",
    "    # list[str] : ë¬¸ìì—´(str)ë¡œ ì´ë£¨ì–´ì§„ ë¦¬ìŠ¤íŠ¸(list)ë§Œ í—ˆìš©\n",
    "    # ì¦‰, ì¬ë£Œ ì´ë¦„ë“¤ì˜ ëª©ë¡ì´ì–´ì•¼ í•¨\n",
    "    # Fieldì˜ descriptionì€ ì´ í•„ë“œê°€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ì„¤ëª…í•˜ëŠ” ë©”íƒ€ì •ë³´\n",
    "    ingredients:list[str]=Field(description=\"ingredients of the dish\") # ìš”ë¦¬ì˜ ì¬ë£Œ ëª©ë¡ì´ë¼ëŠ” ì„¤ëª…\n",
    "\n",
    "    # stepsë¼ëŠ” ë³€ìˆ˜(í•„ë“œ)ë¥¼ ì •ì˜\n",
    "    # list[str] : ë¬¸ìì—´ë¡œ ì´ë£¨ì–´ì§„ ë¦¬ìŠ¤íŠ¸\n",
    "    # ì¦‰, ìš”ë¦¬ ìˆœì„œ(ë‹¨ê³„)ë“¤ì˜ ëª©ë¡\n",
    "    # descriptionì€ ì´ í•„ë“œì˜ ì˜ë¯¸ ì„¤ëª…\n",
    "    steps:list[str]=Field(description=\"steps to make the dish\")  # ìš”ë¦¬ ë§Œë“œëŠ” ë‹¨ê³„ ì„¤ëª…\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2a40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd570b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ Output Parser ì¤‘ í•˜ë‚˜ì¸ PydanticOutputParserë¥¼ ê°€ì ¸ì˜¨ë‹¤\n",
    "# ì´ ë„êµ¬ëŠ” GPTê°€ ì¶œë ¥í•œ JSON í…ìŠ¤íŠ¸ë¥¼ ìš°ë¦¬ê°€ ë§Œë“  Pydantic í´ë˜ìŠ¤(Recipe) ê°ì²´ë¡œ ìë™ ë³€í™˜í•´ì¤€ë‹¤\n",
    "from langchain_classic.output_parsers import PydanticOutputParser\n",
    "\n",
    "# Recipe(Pydantic ëª¨ë¸)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ\n",
    "# LLM ì¶œë ¥ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ Recipe ê°ì²´ë¡œ ë³€í™˜í•˜ëŠ” íŒŒì„œë¥¼ ìƒì„±í•œë‹¤\n",
    "parser=PydanticOutputParser(pydantic_object=Recipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ab9d426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# LLMì—ê²Œ \"ì´ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ë¼\" ë¼ê³  ì§€ì‹œí•˜ëŠ”\n",
    "# í¬ë§· ì•ˆë‚´ ë¬¸êµ¬(format instructions)ë¥¼ ìë™ ìƒì„±í•œë‹¤\n",
    "format_instructions=parser.get_format_instructions()\n",
    "\n",
    "\n",
    "# ìƒì„±ëœ í¬ë§· ì•ˆë‚´ ë¬¸êµ¬ë¥¼ í™”ë©´ì— ì¶œë ¥í•´ì„œ í™•ì¸\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f049553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChainì—ì„œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë§Œë“¤ê¸° ìœ„í•œ PromptTemplate í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤\n",
    "# PromptTemplateì€ GPTì—ê²Œ ë³´ë‚¼ ì§ˆë¬¸(í”„ë¡¬í”„íŠ¸)ì„ ë³€ìˆ˜ ê¸°ë°˜ í…œí”Œë¦¿ í˜•íƒœë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# GPTì—ê²Œ ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ì˜ ê¸°ë³¸ í‹€(ë¬¸ìì—´ í…œí”Œë¦¿)ì„ ì •ì˜\n",
    "# \"\"\" \"\"\" ëŠ” ì—¬ëŸ¬ ì¤„ ë¬¸ìì—´(ë©€í‹°ë¼ì¸ ë¬¸ìì—´)ì„ ë§Œë“¤ê¸° ìœ„í•œ ë¬¸ë²•\n",
    "template=\"\"\"ë‹¤ìŒ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ í•œêµ­ì–´ë¡œ ìƒê°í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "ìš”ë¦¬:{dish}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# PromptTemplate ê°ì²´ ìƒì„±\n",
    "# ì‹¤ì œ GPT í˜¸ì¶œ ì „ì— í”„ë¡¬í”„íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì™„ì„±í•´ì£¼ëŠ” \"í”„ë¡¬í”„íŠ¸ ì„¤ê³„ë„\" ì—­í• \n",
    "prompt=PromptTemplate(\n",
    "    \n",
    "     # ìœ„ì—ì„œ ë§Œë“  ë¬¸ìì—´ í…œí”Œë¦¿ì„ ì‚¬ìš©\n",
    "    template=template,\n",
    "     # ì™¸ë¶€ì—ì„œ ì…ë ¥ë°›ì•„ì•¼ í•˜ëŠ” ë³€ìˆ˜ ëª©ë¡\n",
    "    # {dish} ìë¦¬ì— ë“¤ì–´ê°ˆ ê°’ì„ ë‚˜ì¤‘ì— ì…ë ¥ë°›ê¸° ìœ„í•´ ì„¤ì •\n",
    "    input_variables=[\"dish\"],\n",
    "     # í•­ìƒ ê³ ì •ìœ¼ë¡œ ë¯¸ë¦¬ ì±„ì›Œ ë„£ì„ ë³€ìˆ˜ë“¤\n",
    "    # {format_instructions} ìë¦¬ì— OutputParserê°€ ë§Œë“  JSON ì¶œë ¥ ê·œì¹™ì´ ìë™ ì‚½ì…ë¨\n",
    "    partial_variables={\"format_instructions\":format_instructions}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6b19f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¤ìŒ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ í•œêµ­ì–´ë¡œ ìƒê°í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
      "```\n",
      "\n",
      "ìš”ë¦¬:ì¹´ë ˆ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplateì— ì‹¤ì œ ê°’ì„ ë„£ì–´ì„œ ìµœì¢… í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ì„ ìƒì„±í•œë‹¤\n",
    "# {dish} ìë¦¬ì— \"ì¹´ë ˆ\"ê°€ ìë™ìœ¼ë¡œ ì¹˜í™˜ëœë‹¤\n",
    "formatted_prompt=prompt.format(dish=\"ì¹´ë ˆ\")\n",
    "\n",
    "\n",
    "# GPTì—ê²Œ ë³´ë‚´ê¸° ì „ì— ì‹¤ì œ ë§Œë“¤ì–´ì§„ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ì¶œë ¥\n",
    "# ë””ë²„ê¹… ë° í˜•ì‹ í™•ì¸ ìš©ë„\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1f7d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ingredients\": [\n",
      "    \"ê°ì 2ê°œ\",\n",
      "    \"ë‹¹ê·¼ 1ê°œ\",\n",
      "    \"ì–‘íŒŒ 1ê°œ\",\n",
      "    \"ë‹­ê³ ê¸° 300g\",\n",
      "    \"ì¹´ë ˆ ê°€ë£¨ 3í°ìˆ \",\n",
      "    \"ì‹ìš©ìœ  2í°ìˆ \",\n",
      "    \"ë¬¼ 500ml\",\n",
      "    \"ì†Œê¸ˆ ì•½ê°„\",\n",
      "    \"í›„ì¶” ì•½ê°„\"\n",
      "  ],\n",
      "  \"steps\": [\n",
      "    \"ê°ì, ë‹¹ê·¼, ì–‘íŒŒë¥¼ ê¹ë‘‘ì°ê¸° í•œë‹¤.\",\n",
      "    \"ë‹­ê³ ê¸°ëŠ” í•œ ì… í¬ê¸°ë¡œ ìë¥¸ë‹¤.\",\n",
      "    \"ëƒ„ë¹„ì— ì‹ìš©ìœ ë¥¼ ë‘ë¥´ê³  ì¤‘ë¶ˆì—ì„œ ì–‘íŒŒë¥¼ ë³¶ì•„ í–¥ì„ ë‚¸ë‹¤.\",\n",
      "    \"ë‹­ê³ ê¸°ë¥¼ ë„£ê³  ê²‰ë©´ì´ ìµì„ ë•Œê¹Œì§€ ë³¶ëŠ”ë‹¤.\",\n",
      "    \"ê°ìì™€ ë‹¹ê·¼ì„ ë„£ê³  í•¨ê»˜ ë³¶ëŠ”ë‹¤.\",\n",
      "    \"ë¬¼ 500mlë¥¼ ë¶“ê³  ë“ì¸ë‹¤.\",\n",
      "    \"ì¬ë£Œê°€ ìµìœ¼ë©´ ì¹´ë ˆ ê°€ë£¨ë¥¼ ë„£ê³  ì˜ ì €ì–´ê°€ë©° ë“ì¸ë‹¤.\",\n",
      "    \"ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„ ë§ì¶˜ë‹¤.\",\n",
      "    \"ì¹´ë ˆê°€ ê±¸ì­‰í•´ì§ˆ ë•Œê¹Œì§€ ì•½í•œ ë¶ˆì—ì„œ 10ë¶„ ì •ë„ ë” ë“ì¸ë‹¤.\",\n",
      "    \"ì™„ì„±ëœ ì¹´ë ˆë¥¼ ë°¥ê³¼ í•¨ê»˜ ë‚¸ë‹¤.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# OpenAI GPT ëª¨ë¸ì„ LangChainì—ì„œ ì‰½ê²Œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ChatOpenAI í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤\n",
    "from langchain_openai import ChatOpenAI\n",
    "# GPT ëŒ€í™” ë©”ì‹œì§€ í˜•ì‹ ì¤‘ \"ì‚¬ëŒì´ ë³´ë‚¸ ë©”ì‹œì§€\" íƒ€ì…ì¸ HumanMessageë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤\n",
    "from langchain_classic.schema import HumanMessage\n",
    "\n",
    "# GPT ëª¨ë¸ ê°ì²´ ìƒì„±\n",
    "# model_name : ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì§€ì •\n",
    "# temperature : ì‘ë‹µì˜ ëœë¤ì„±(ì°½ì˜ì„±) ì¡°ì ˆ (0ì´ë©´ ê°€ì¥ ì•ˆì •ì ì¸ ì¶œë ¥)\n",
    "chat=ChatOpenAI(model_name=\"gpt-4.1-mini\",temperature=0)\n",
    "\n",
    "# GPTì—ê²Œ ì „ë‹¬í•  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "# HumanMessageëŠ” \"ì‚¬ìš©ì ì§ˆë¬¸\" ì—­í• \n",
    "# contentì—ëŠ” ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ì„ ë„£ëŠ”ë‹¤\n",
    "messages=[HumanMessage(content=formatted_prompt)]\n",
    "\n",
    "# GPT ëª¨ë¸ì„ ì‹¤ì œë¡œ í˜¸ì¶œí•˜ëŠ” ë¶€ë¶„\n",
    "# messagesë¥¼ OpenAI ì„œë²„ë¡œ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ì•„ì˜¨ë‹¤\n",
    "output=chat.invoke(messages)\n",
    "\n",
    "\n",
    "# GPTê°€ ìƒì„±í•œ ìµœì¢… ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶œë ¥\n",
    "# output.contentì—ëŠ” GPTê°€ ë°˜í™˜í•œ ë¬¸ìì—´(JSON í˜•íƒœ)ì´ ë“¤ì–´ìˆë‹¤\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8f216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Recipe'>\n",
      "ingredients=['ê°ì 2ê°œ', 'ë‹¹ê·¼ 1ê°œ', 'ì–‘íŒŒ 1ê°œ', 'ë‹­ê³ ê¸° 300g', 'ì¹´ë ˆ ê°€ë£¨ 3í°ìˆ ', 'ì‹ìš©ìœ  2í°ìˆ ', 'ë¬¼ 500ml', 'ì†Œê¸ˆ ì•½ê°„', 'í›„ì¶” ì•½ê°„'] steps=['ê°ì, ë‹¹ê·¼, ì–‘íŒŒë¥¼ ê¹ë‘‘ì°ê¸° í•œë‹¤.', 'ë‹­ê³ ê¸°ëŠ” í•œ ì… í¬ê¸°ë¡œ ìë¥¸ë‹¤.', 'ëƒ„ë¹„ì— ì‹ìš©ìœ ë¥¼ ë‘ë¥´ê³  ì¤‘ë¶ˆì—ì„œ ì–‘íŒŒë¥¼ ë³¶ì•„ í–¥ì„ ë‚¸ë‹¤.', 'ë‹­ê³ ê¸°ë¥¼ ë„£ê³  ê²‰ë©´ì´ ìµì„ ë•Œê¹Œì§€ ë³¶ëŠ”ë‹¤.', 'ê°ìì™€ ë‹¹ê·¼ì„ ë„£ê³  í•¨ê»˜ ë³¶ëŠ”ë‹¤.', 'ë¬¼ 500mlë¥¼ ë¶“ê³  ë“ì¸ë‹¤.', 'ì¬ë£Œê°€ ìµìœ¼ë©´ ì¹´ë ˆ ê°€ë£¨ë¥¼ ë„£ê³  ì˜ ì €ì–´ê°€ë©° ë“ì¸ë‹¤.', 'ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„ ë§ì¶˜ë‹¤.', 'ì¹´ë ˆê°€ ê±¸ì­‰í•´ì§ˆ ë•Œê¹Œì§€ ì•½í•œ ë¶ˆì—ì„œ 10ë¶„ ì •ë„ ë” ë“ì¸ë‹¤.', 'ì™„ì„±ëœ ì¹´ë ˆë¥¼ ë°¥ê³¼ í•¨ê»˜ ë‚¸ë‹¤.']\n"
     ]
    }
   ],
   "source": [
    "# parser.parse()ëŠ” GPTê°€ ìƒì„±í•œ í…ìŠ¤íŠ¸ ì¶œë ¥ ê²°ê³¼ë¥¼\n",
    "# Pydantic ëª¨ë¸(Recipe í´ë˜ìŠ¤) í˜•íƒœì˜ ê°ì²´ë¡œ ë³€í™˜í•´ì£¼ëŠ” í•¨ìˆ˜ì´ë‹¤\n",
    "# output.content ëŠ” ChatGPTê°€ ìƒì„±í•œ \"ìˆœìˆ˜ í…ìŠ¤íŠ¸ ì‘ë‹µ\" ë¶€ë¶„ì´ë‹¤\n",
    "# ì´ ì¤„ì´ ì‹¤í–‰ë˜ë©´:\n",
    "# 1) JSON í˜•íƒœ ë¬¸ìì—´ íŒŒì‹±\n",
    "# 2) Recipe êµ¬ì¡° ê²€ì¦\n",
    "# 3) Recipe ê°ì²´ ìƒì„±\n",
    "# ì´ ì„¸ ë‹¨ê³„ê°€ ìë™ìœ¼ë¡œ ìˆ˜í–‰ëœë‹¤\n",
    "recipe=parser.parse(output.content)\n",
    "\n",
    "# recipe ë³€ìˆ˜ì— ì €ì¥ëœ ë°ì´í„°ì˜ íƒ€ì…(ìë£Œí˜•)ì„ ì¶œë ¥í•œë‹¤\n",
    "# ì‹¤ì œë¡œ Recipe í´ë˜ìŠ¤ ê°ì²´ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•¨ì´ë‹¤\n",
    "print(type(recipe))\n",
    "\n",
    "# Recipe ê°ì²´ì˜ ë‚´ìš©ì„ ì¶œë ¥í•œë‹¤\n",
    "# Pydanticì€ ê°ì²´ë¥¼ ì¶œë ¥í•  ë•Œ í•„ë“œ ì´ë¦„ê³¼ ê°’ì„ ë³´ê¸° ì¢‹ê²Œ í‘œì‹œí•´ì¤€ë‹¤\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChainì—ì„œ OpenAI ì±„íŒ… ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤\n",
    "from langchain_openai import ChatOpenAI\n",
    "# GPTê°€ ìƒì„±í•œ ì¶œë ¥ ê²°ê³¼ë¥¼ Pydantic ëª¨ë¸ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ íŒŒì„œ í´ë˜ìŠ¤\n",
    "from langchain_classic.output_parsers import PydanticOutputParser\n",
    "# í”„ë¡¬í”„íŠ¸(ì§ˆë¬¸ í…œí”Œë¦¿)ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ í´ë˜ìŠ¤\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "# Pydantic ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ë°ì´í„° ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•œ ê¸°ë³¸ í´ë˜ìŠ¤ì™€ í•„ë“œ ì„¤ì • ë„êµ¬\n",
    "from pydantic import BaseModel,Field\n",
    "\n",
    "\n",
    "# Recipe ë¼ëŠ” ë°ì´í„° êµ¬ì¡°(ì¶œë ¥ í¬ë§·)ë¥¼ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤\n",
    "# GPTê°€ ìƒì„±í•œ ê²°ê³¼ë¥¼ ì´ í˜•íƒœë¡œ ë°›ê¸° ìœ„í•´ ì‚¬ìš©í•œë‹¤\n",
    "class Recipe(BaseModel):\n",
    "    # ingredients í•„ë“œëŠ” ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ íƒ€ì…\n",
    "    # ì˜ˆ: [\"ê°ì\", \"ì†Œê³ ê¸°\", \"ì–‘íŒŒ\"]\n",
    "    ingredients:list[str]=Field(description=\"ingredients of the dish\")  # GPTì—ê²Œ í•„ë“œ ì˜ë¯¸ë¥¼ ì•Œë ¤ì£¼ëŠ” ì„¤ëª…\n",
    "    # steps í•„ë“œëŠ” ì¡°ë¦¬ ê³¼ì • ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸\n",
    "    # ì˜ˆ: [\"ê³ ê¸°ë¥¼ ë³¶ëŠ”ë‹¤\", \"ê°ìë¥¼ ë„£ëŠ”ë‹¤\"]\n",
    "    steps:list[str]=Field(description=\"steps to make the dish\")  # GPT ì¶œë ¥ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ íŒíŠ¸\n",
    "\n",
    "# PydanticOutputParser ìƒì„±\n",
    "# GPT ì¶œë ¥ ê²°ê³¼ë¥¼ Recipe í´ë˜ìŠ¤ í˜•íƒœë¡œ ìë™ ë³€í™˜í•˜ëŠ” ì—­í• \n",
    "output_parser=PydanticOutputParser(pydantic_object=Recipe) # ë³€í™˜ ê¸°ì¤€ì´ ë  Pydantic ëª¨ë¸ ì§€ì •\n",
    "\n",
    "\n",
    "# GPTì—ê²Œ ë³´ë‚¼ í”„ë¡¬í”„íŠ¸(ì§ˆë¬¸) í…œí”Œë¦¿ ì‘ì„±\n",
    "template=\"\"\"\n",
    "ë‹¤ìŒ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ í•œêµ­ì–´ë¡œ ìƒê°í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "ìš”ë¦¬: {dish}\n",
    "\"\"\"\n",
    "\n",
    "# PromptTemplate ê°ì²´ ìƒì„±\n",
    "prompt=PromptTemplate(\n",
    "     # ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¬¸ìì—´\n",
    "    template=template,\n",
    "     # ì‚¬ìš©ìê°€ ì…ë ¥í•  ë³€ìˆ˜ ëª©ë¡\n",
    "    # ì—¬ê¸°ì„œëŠ” ìš”ë¦¬ ì´ë¦„(dish)ë§Œ ì™¸ë¶€ì—ì„œ ë°›ëŠ”ë‹¤\n",
    "    input_variables=['dish'],\n",
    "    # ë¯¸ë¦¬ ìë™ìœ¼ë¡œ ì±„ì›Œ ë„£ì„ ë³€ìˆ˜ë“¤\n",
    "    # format_instructionsëŠ” GPTì—ê²Œ ì¶œë ¥ í˜•ì‹ì„ ì•Œë ¤ì£¼ëŠ” ìë™ ìƒì„± ë¬¸êµ¬\n",
    "    partial_variables={\"format_instructions\":output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# ChatGPT ëª¨ë¸ ê°ì²´ ìƒì„±\n",
    " # ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„\n",
    "   # temperature = 0 â†’ ì¶œë ¥ ëœë¤ì„± ì œê±°\n",
    "    # JSON êµ¬ì¡° ê¹¨ì§€ëŠ” ê²ƒì„ ë°©ì§€í•˜ê³  ì•ˆì •ì ì¸ ì¶œë ¥ ìœ ë„\n",
    "chat=ChatOpenAI(model_name='gpt-4.1-mini',temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa8e730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7824\\2290157430.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use `RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain=LLMChain(prompt=prompt,llm=chat,output_parser=output_parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'dish': 'ì¹´ë ˆ', 'text': Recipe(ingredients=['ë‹­ê³ ê¸° 300g', 'ê°ì 2ê°œ', 'ë‹¹ê·¼ 1ê°œ', 'ì–‘íŒŒ 1ê°œ', 'ì¹´ë ˆ ê°€ë£¨ 3í°ìˆ ', 'ì‹ìš©ìœ  2í°ìˆ ', 'ë¬¼ 600ml', 'ì†Œê¸ˆ ì•½ê°„', 'í›„ì¶” ì•½ê°„', 'ë°¥ 2ê³µê¸°'], steps=['ë‹­ê³ ê¸°ëŠ” í•œ ì… í¬ê¸°ë¡œ ì°ê³ , ê°ìì™€ ë‹¹ê·¼ì€ ê»ì§ˆì„ ë²—ê²¨ í¼ì§í•˜ê²Œ ìë¥¸ë‹¤.', 'ì–‘íŒŒëŠ” ì±„ ì¬ë‹¤.', 'ëƒ„ë¹„ì— ì‹ìš©ìœ ë¥¼ ë‘ë¥´ê³  ì¤‘ë¶ˆì—ì„œ ì–‘íŒŒë¥¼ íˆ¬ëª…í•´ì§ˆ ë•Œê¹Œì§€ ë³¶ëŠ”ë‹¤.', 'ë‹­ê³ ê¸°ë¥¼ ë„£ê³  ê²‰ë©´ì´ í•˜ì–—ê²Œ ìµì„ ë•Œê¹Œì§€ ë³¶ëŠ”ë‹¤.', 'ê°ìì™€ ë‹¹ê·¼ì„ ë„£ê³  í•¨ê»˜ ë³¶ëŠ”ë‹¤.', 'ë¬¼ 600mlë¥¼ ë¶“ê³  ë“ì¸ë‹¤.', 'ë“ê¸° ì‹œì‘í•˜ë©´ ì¤‘ì•½ë¶ˆë¡œ ì¤„ì´ê³  ëšœê»‘ì„ ë®ì–´ 15ë¶„ê°„ ë“ì¸ë‹¤.', 'ì¹´ë ˆ ê°€ë£¨ë¥¼ ë„£ê³  ì˜ ì €ì–´ê°€ë©° 5ë¶„ê°„ ë” ë“ì¸ë‹¤.', 'ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„ ë§ì¶˜ë‹¤.', 'ê·¸ë¦‡ì— ë°¥ì„ ë‹´ê³  ì¹´ë ˆë¥¼ ë¶€ì–´ ì™„ì„±í•œë‹¤.'])}\n"
     ]
    }
   ],
   "source": [
    "# LangChainì—ì„œ \"ì²´ì¸(Chain)\" ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” LLMChain í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤\n",
    "# Chainì€ ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ì²˜ëŸ¼ ì—°ê²°í•´ì£¼ëŠ” ë„êµ¬ì´ë‹¤\n",
    "from langchain_classic.chains import LLMChain\n",
    "\n",
    "# LLMChain ê°ì²´ ìƒì„±\n",
    "# í”„ë¡¬í”„íŠ¸ + LLM + ì¶œë ¥ íŒŒì„œë¥¼ í•˜ë‚˜ë¡œ ë¬¶ëŠ”ë‹¤\n",
    "chain=LLMChain(prompt=prompt, # ì´ì „ì— ë§Œë“  PromptTemplate (ì§ˆë¬¸ í…œí”Œë¦¿)\n",
    "               llm=chat,   # ì´ì „ì— ë§Œë“  ChatOpenAI ëª¨ë¸ ê°ì²´ (GPT)\n",
    "               output_parser=output_parser) # GPT ì¶œë ¥ ê²°ê³¼ë¥¼ Recipe ê°ì²´ë¡œ ë³€í™˜í•´ì£¼ëŠ” íŒŒì„œ\n",
    "\n",
    "\n",
    "\n",
    "# ì²´ì¸ì„ ì‹¤í–‰(invoke)\n",
    "# \"ì¹´ë ˆ\" ê°’ì„ promptì˜ {dish} ë³€ìˆ˜ì— ìë™ìœ¼ë¡œ ë„£ê³ \n",
    "# GPT í˜¸ì¶œ + ì¶œë ¥ íŒŒì‹±ê¹Œì§€ í•œ ë²ˆì— ì²˜ë¦¬í•œë‹¤\n",
    "recipe=chain.invoke(\"ì¹´ë ˆ\")\n",
    "\n",
    "# recipe ë³€ìˆ˜ì— ì €ì¥ëœ ê²°ê³¼ì˜ íƒ€ì…(ìë£Œí˜•)ì„ ì¶œë ¥í•œë‹¤\n",
    "# ì‹¤ì œë¡œ Recipe í´ë˜ìŠ¤ ê°ì²´ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•¨ì´ë‹¤\n",
    "print(type(recipe))\n",
    "\n",
    "# ìµœì¢… ìƒì„±ëœ Recipe ê°ì²´ ë‚´ìš©ì„ ì¶œë ¥í•œë‹¤\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChainì—ì„œ OpenAI ì±„íŒ… ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ChatOpenAI í´ë˜ìŠ¤ë¡œ\n",
    "# GPT ëª¨ë¸ê³¼ í†µì‹ í•  ìˆ˜ ìˆëŠ” ê°ì²´ë¥¼ ìƒì„±í•œë‹¤\n",
    "\n",
    "                 # ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„ ì§€ì •\n",
    "                # gpt-4.1-miniëŠ” ë¹ ë¥´ê³  ë¹„ìš©ì´ ì €ë ´í•œ ëª¨ë¸\n",
    "chat=ChatOpenAI(model_name='gpt-4.1-mini',\n",
    "                 # temperatureëŠ” ë‹µë³€ì˜ ëœë¤ì„±(ì°½ì˜ì„±)ì„ ì¡°ì ˆí•˜ëŠ” ê°’\n",
    "                 # 0ì´ë©´ í•­ìƒ ê°€ì¥ ì•ˆì •ì ì´ê³  ì¼ê´€ëœ ë‹µë³€ì„ ìƒì„±\n",
    "                temperature=0)\n",
    "\n",
    "\n",
    "# Chain-of-Thought(ë‹¨ê³„ë³„ ì‚¬ê³ )ë¥¼ ìœ ë„í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¬¸ìì—´\n",
    "# \"\"\" \"\"\" ëŠ” ì—¬ëŸ¬ ì¤„ ë¬¸ìì—´(ë©€í‹°ë¼ì¸ ë¬¸ìì—´) ì‘ì„± ë¬¸ë²•\n",
    "cot_template=\"\"\"ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”\n",
    "\n",
    "ì§ˆë¬¸:{question}\n",
    "\n",
    "ë‹¨ê³„ë³„ë¡œ ìƒê°í•´ ë´…ì‹œë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# PromptTemplate ê°ì²´ ìƒì„±\n",
    "# ì§ˆë¬¸ í…œí”Œë¦¿ì— ì‹¤ì œ ê°’ì„ ì±„ì›Œ ë„£ê¸° ìœ„í•œ LangChain ë„êµ¬\n",
    "cot_prompt=PromptTemplate(\n",
    "    # ì™¸ë¶€ì—ì„œ ì…ë ¥ë°›ì„ ë³€ìˆ˜ ëª©ë¡\n",
    "    # ì—¬ê¸°ì„œëŠ” {question} í•˜ë‚˜ë§Œ ì‚¬ìš©\n",
    "    input_variables=[\"question\"],\n",
    "     # ìœ„ì—ì„œ ì‘ì„±í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¬¸ìì—´ ë“±ë¡\n",
    "    template=cot_template,\n",
    ")\n",
    "\n",
    "# LLMChain ê°ì²´ ìƒì„±\n",
    "# í”„ë¡¬í”„íŠ¸ + GPT ëª¨ë¸ì„ í•˜ë‚˜ì˜ ìë™ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¬¶ëŠ”ë‹¤\n",
    "cot_chain=LLMChain(llm=chat, # ì‚¬ìš©í•  GPT ëª¨ë¸ ê°ì²´\n",
    "                   prompt=cot_prompt)  # ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fe68d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìš”ì•½ ì‘ì—…ì— ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸(ì§ˆë¬¸) í…œí”Œë¦¿ ë¬¸ìì—´ì„ ì •ì˜í•œë‹¤\n",
    "# \"\"\" \"\"\" ëŠ” ì—¬ëŸ¬ ì¤„ ë¬¸ìì—´(ë©€í‹°ë¼ì¸ ë¬¸ìì—´) ì‘ì„± ë¬¸ë²•ì´ë‹¤\n",
    "summarize_template=\"\"\"ë‹¤ìŒ ë¬¸ì¥ì„ ê²°ë¡ ë§Œ ê°„ë‹¨íˆ ìš”ì•½í•˜ì„¸ìš”.\n",
    "\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "# PromptTemplate ê°ì²´ ìƒì„±\n",
    "# ìš”ì•½ í”„ë¡¬í”„íŠ¸ë¥¼ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿ í˜•íƒœë¡œ ë“±ë¡í•œë‹¤\n",
    "summarize_prompt=PromptTemplate(\n",
    "    # ì™¸ë¶€ì—ì„œ ì…ë ¥ë°›ì„ ë³€ìˆ˜ ì´ë¦„ ëª©ë¡\n",
    "    # ì—¬ê¸°ì„œëŠ” {input} í•˜ë‚˜ë§Œ ì‚¬ìš©\n",
    "    input_variables=[\"input\"],\n",
    "\n",
    "     # ìœ„ì—ì„œ ë§Œë“  ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¬¸ìì—´ ì—°ê²°\n",
    "    template=summarize_template,\n",
    ")\n",
    "\n",
    "# LLMChain ê°ì²´ ìƒì„±\n",
    "# GPT ëª¨ë¸(chat)ê³¼ ìš”ì•½ í”„ë¡¬í”„íŠ¸(summarize_prompt)ë¥¼\n",
    "# í•˜ë‚˜ì˜ ìë™ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¬¶ëŠ”ë‹¤\n",
    "summarize_chain=LLMChain(llm=chat, # ì‚¬ìš©í•  GPT ëª¨ë¸ ê°ì²´\n",
    "                         prompt=summarize_prompt) # ì‚¬ìš©í•  ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00355e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‚¨ì€ ì‚¬ê³¼ëŠ” 10ê°œì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì—¬ëŸ¬ ê°œì˜ ì²´ì¸ì„ \"ìˆœì„œëŒ€ë¡œ\" ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” SimpleSequentialChain í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤\n",
    "from langchain_classic.chains import SimpleSequentialChain\n",
    "\n",
    "# ë‘ ê°œì˜ ì²´ì¸(cot_chain, summarize_chain)ì„ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ ì²´ì¸ìœ¼ë¡œ ë¬¶ëŠ”ë‹¤\n",
    "# ì‹¤í–‰ ìˆœì„œ:\n",
    "# 1) cot_chain ì‹¤í–‰ (ë¬¸ì œ í’€ì´ + ë‹¨ê³„ë³„ ì‚¬ê³ )\n",
    "# 2) summarize_chain ì‹¤í–‰ (ê²°ë¡ ë§Œ ìš”ì•½)\n",
    "cot_summarize_chain=SimpleSequentialChain(chains=[cot_chain,summarize_chain])\n",
    "\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ì²´ì¸ì„ ì‹¤í–‰í•œë‹¤\n",
    "# ì•„ë˜ì˜ ê¸´ ë¬¸ì¥ì´ ì²« ë²ˆì§¸ ì²´ì¸(cot_chain)ì˜ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤\n",
    "result=cot_summarize_chain.invoke(\n",
    "    \"\"\" ì €ëŠ” ì‹œì¥ì— ê°€ì„œ ì‚¬ê³¼ 10ê°œë¥¼ ìƒ€ìŠµë‹ˆë‹¤.\n",
    "    ì´ì›ƒì—ê²Œ 2ê°œ, ìˆ˜ë¦¬ê³µì—ê²Œ 2ê°œë¥¼ ì£¼ì—ˆìŠµë‹ˆë‹¤.\n",
    "    ê·¸ëŸ° ë‹¤ìŒì— ì‚¬ê³¼ 5ê°œë¥¼ ë” ì‚¬ì„œ 1ê°œë¥¼ ë¨¹ì—ˆìŠµë‹ˆë‹¤.\n",
    "    ë‚¨ì€ ê°œìˆ˜ëŠ” ëª‡ê°œì¸ê°€ìš”?\n",
    "    \"\"\"\n",
    "    \n",
    ")\n",
    "# ìµœì¢… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì—ì„œ \"output\" ê°’ë§Œ êº¼ë‚´ì„œ ì¶œë ¥í•œë‹¤\n",
    "# outputì—ëŠ” summarize_chainì˜ ìµœì¢… ê²°ê³¼ê°€ ë“¤ì–´ ìˆë‹¤\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dad6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23704\\1794828294.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferMemory()\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23704\\1794828294.py:6: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use `langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation=ConversationChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI : Hello! Itâ€™s great to chat with you. Whatâ€™s on your mind today? Whether itâ€™s a question, a story, or just some friendly banter, Iâ€™m all ears!\n",
      "AI : ì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”. ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë– ì„¸ìš”? ë¬´ì—‡ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?\n",
      "AI : ë¬¼ë¡ ì´ì£ ! ì•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´ ë“œë¦´ê²Œìš”. ì–´ë–¤ ì£¼ì œì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ì‹¶ìœ¼ì„¸ìš”? ê¶ê¸ˆí•œ ì ì´ë‚˜ ë‚˜ëˆ„ê³  ì‹¶ì€ ì´ì•¼ê¸°ê°€ ìˆìœ¼ë©´ í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "AI : ì˜¤ëŠ˜ì˜ ë‚ ì”¨ì— ëŒ€í•´ ì•Œë ¤ë“œë¦¬ê³  ì‹¶ì§€ë§Œ, ì €ëŠ” ì‹¤ì‹œê°„ ì •ë³´ì— ì ‘ê·¼í•  ìˆ˜ ì—†ì–´ì„œ í˜„ì¬ ìœ„ì¹˜ì˜ ì •í™•í•œ ë‚ ì”¨ë¥¼ ì•Œë ¤ë“œë¦¬ê¸° ì–´ë ¤ì›Œìš”. ëŒ€ì‹ , ë‚ ì”¨ë¥¼ í™•ì¸í•˜ë ¤ë©´ ìŠ¤ë§ˆíŠ¸í°ì˜ ë‚ ì”¨ ì•±ì´ë‚˜ ì¸í„°ë„·ì˜ ê¸°ìƒì²­ ì‚¬ì´íŠ¸ë¥¼ ì´ìš©í•´ ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œë“œë ¤ìš”. í˜¹ì‹œ íŠ¹ì • ì§€ì—­ì˜ ì¼ë°˜ì ì¸ ê¸°í›„ë‚˜ ê³„ì ˆë³„ ë‚ ì”¨ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹œë©´ ê·¸ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ” ìì„¸íˆ ì„¤ëª…í•´ ë“œë¦´ ìˆ˜ ìˆì–´ìš”!\n",
      "AI : ì£„ì†¡í•˜ì§€ë§Œ ì €ëŠ” ì‹¤ì‹œê°„ ë‚ ì”¨ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ì—†ì–´ìš”. ëŒ€ì‹ , ì›í•˜ì‹œëŠ” ì§€ì—­ì˜ ê³„ì ˆë³„ ë‚ ì”¨ íŠ¹ì§•ì´ë‚˜ ì¼ë°˜ì ì¸ ê¸°í›„ì— ëŒ€í•´ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ì–´ëŠ ì§€ì—­ì˜ ë‚ ì”¨ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?\n",
      "(ëŒ€í™” ì¢…ë£Œ)\n"
     ]
    }
   ],
   "source": [
    "# LangChainì—ì„œ \"ëŒ€í™” ì „ìš© ì²´ì¸\" ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ConversationChain í´ë˜ìŠ¤ import\n",
    "from langchain_classic.chains import ConversationChain\n",
    "# OpenAI GPT ì±„íŒ… ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ LangChain í´ë˜ìŠ¤ import\n",
    "from langchain_openai import ChatOpenAI\n",
    "# ëŒ€í™” ë‚´ìš©ì„ ì €ì¥(ê¸°ì–µ)í•˜ê¸° ìœ„í•œ ë©”ëª¨ë¦¬ í´ë˜ìŠ¤ import\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "# ChatOpenAI ê°ì²´ ìƒì„±\n",
    "# OpenAI GPT ëª¨ë¸ê³¼ ì‹¤ì œë¡œ í†µì‹ í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ ì—­í• \n",
    "chat=ChatOpenAI(model_name='gpt-4.1-mini',  # ì‚¬ìš©í•  GPT ëª¨ë¸ ì´ë¦„\n",
    "                temperature=0)              # temperature=0 â†’ ì‘ë‹µì„ ìµœëŒ€í•œ ì•ˆì •ì ì´ê³  ì¼ê´€ë˜ê²Œ ìƒì„±\n",
    "\n",
    "# ConversationChain ê°ì²´ ìƒì„±\n",
    "# GPT ëª¨ë¸ + ëŒ€í™” ë©”ëª¨ë¦¬ë¥¼ í•˜ë‚˜ì˜ ëŒ€í™” íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¬¶ëŠ”ë‹¤\n",
    "conversation=ConversationChain(\n",
    "    llm=chat,  # ì‚¬ìš©í•  GPT ëª¨ë¸ ì§€ì •\n",
    "\n",
    "     # ëŒ€í™” ë‚´ìš©ì„ ìë™ìœ¼ë¡œ ì €ì¥í•˜ëŠ” ë©”ëª¨ë¦¬ ê°ì²´\n",
    "    # ì´ì „ ëŒ€í™”ë¥¼ ëª¨ë‘ ê¸°ì–µí•´ì„œ ë‹¤ìŒ ì§ˆë¬¸ì— ë°˜ì˜\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "# ë¬´í•œ ë°˜ë³µ ë£¨í”„\n",
    "# ì‚¬ìš©ìê°€ \"ë\"ì„ ì…ë ¥í•  ë•Œê¹Œì§€ ê³„ì† ëŒ€í™”\n",
    "while True:\n",
    "    # ì‚¬ìš©ìë¡œë¶€í„° ì½˜ì†” ì…ë ¥ ë°›ê¸°\n",
    "    # í™”ë©´ì— \"You : \"ë¥¼ í‘œì‹œí•˜ê³  ì…ë ¥ ëŒ€ê¸°\n",
    "    user_message=input(\"You : \")\n",
    "\n",
    "     # ì‚¬ìš©ìê°€ \"ë\" ì´ë¼ê³  ì…ë ¥í•˜ë©´ ëŒ€í™” ì¢…ë£Œ\n",
    "    if user_message == \"ë\":\n",
    "         # ì¢…ë£Œ ë©”ì‹œì§€ ì¶œë ¥\n",
    "        print(\"(ëŒ€í™” ì¢…ë£Œ)\")\n",
    "        # while ë°˜ë³µë¬¸ íƒˆì¶œ\n",
    "        break\n",
    "    # ConversationChain ì‹¤í–‰\n",
    "    # ì‚¬ìš©ìì˜ ì…ë ¥ì„ GPTì— ì „ë‹¬í•˜ê³ \n",
    "    # ì´ì „ ëŒ€í™” ë‚´ìš©ê¹Œì§€ í•¨ê»˜ ê³ ë ¤í•´ì„œ ë‹µë³€ ìƒì„±\n",
    "\n",
    "                                    # GPTì—ê²Œ ì „ë‹¬í•  ì‚¬ìš©ì ì…ë ¥ # ë°˜í™˜ëœ ê²°ê³¼ ì¤‘ \"AI ì‘ë‹µ í…ìŠ¤íŠ¸\"ë§Œ ì¶”ì¶œ\n",
    "    ai_message=conversation.invoke(input=user_message)['response']\n",
    "    # AIê°€ ìƒì„±í•œ ë‹µë³€ì„ ì½˜ì†”ì— ì¶œë ¥\n",
    "    print(f\"AI : {ai_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6050bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChainì—ì„œ OpenAI ì±„íŒ… ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ChatOpenAI í´ë˜ìŠ¤ import\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatGPT ë©”ì‹œì§€ ì—­í• (assistant, user, system)ì— í•´ë‹¹í•˜ëŠ”\n",
    "# ë©”ì‹œì§€ ê°ì²´ í´ë˜ìŠ¤ë“¤ì„ ë¶ˆëŸ¬ì˜¨ë‹¤\n",
    "from langchain_classic.schema import AIMessage,HumanMessage,SystemMessage\n",
    "\n",
    "# ChatOpenAI ê°ì²´ ìƒì„±\n",
    "# OpenAI GPT ëª¨ë¸ê³¼ ì‹¤ì œë¡œ í†µì‹ í•  í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "chat=ChatOpenAI(model_name='gpt-4.1-mini', # ì‚¬ìš©í•  GPT ëª¨ë¸ ì´ë¦„ ì§€ì •\n",
    "                temperature=0) # temperature=0 â†’ ì‘ë‹µì˜ ëœë¤ì„± ì œê±° (í•­ìƒ ë¹„ìŠ·í•˜ê³  ì•ˆì •ì ì¸ ë‹µë³€ ìƒì„±)\n",
    "\n",
    "# ChatGPTì—ê²Œ ì „ë‹¬í•  \"ëŒ€í™” ë©”ì‹œì§€ ëª©ë¡\" ìƒì„±\n",
    "# messagesëŠ” ëŒ€í™” íë¦„ì„ ê·¸ëŒ€ë¡œ ì¬í˜„í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ì´ë‹¤\n",
    "messages=[\n",
    "     # SystemMessage\n",
    "    # AIì˜ ì—­í• ê³¼ ì„±ê²©ì„ ì§€ì •í•˜ëŠ” ë©”ì‹œì§€\n",
    "    # ëŒ€í™” ê·œì¹™, ìŠ¤íƒ€ì¼, í–‰ë™ ë°©ì¹¨ ì„¤ì • ìš©ë„\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "     # HumanMessage\n",
    "    # ì‹¤ì œ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì²« ë²ˆì§¸ ë©”ì‹œì§€\n",
    "    HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš” . ì €ëŠ” ì¡´ì´ë¼ê³  í•©ë‹ˆë‹¤!\"),\n",
    "    # AIMessage\n",
    "    # ì´ì „ì— AIê°€ í–ˆë˜ ë‹µë³€ì„ ëŒ€í™” ê¸°ë¡ìœ¼ë¡œ ì¶”ê°€\n",
    "    # ì´ì „ ì‘ë‹µì„ í¬í•¨ì‹œí‚¤ë©´ ë¬¸ë§¥ì„ ì´ì–´ê°ˆ ìˆ˜ ìˆë‹¤\n",
    "    AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”, ì¡´ ë‹˜! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\"),\n",
    "    \n",
    "    # HumanMessage\n",
    "    # ì‚¬ìš©ìê°€ ë‹¤ì‹œ ì§ˆë¬¸í•œ ë‚´ìš©\n",
    "    HumanMessage(content=\"ì œì´ë¦„ì„ ì•„ì„¸ìš”?\")\n",
    "]\n",
    "result=chat.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df68d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
