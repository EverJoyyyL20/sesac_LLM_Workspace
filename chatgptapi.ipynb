{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc86ea4",
   "metadata": {},
   "source": [
    "# ChatGPT를 API에서 이용하기\n",
    "\n",
    "## 입력과 출력의 길이 제한 및 요금에 영향을 주는 토큰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4a6033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tiktoken in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.26.0->tiktoken) (2.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc1cfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# OpenAI에서 만든 토큰화(Tokenization) 라이브러리 불러오기\n",
    "# GPT 모델이 문장을 어떻게 쪼개는지 그대로 재현할 수 있다\n",
    "import tiktoken\n",
    "\n",
    "# 토큰 개수를 알고 싶은 문장을 문자열(String)로 저장\n",
    "# 아직 이 상태에서는 그냥 사람이 읽는 문장일 뿐이다\n",
    "text = \"It’s easy to make something cool with LLMs, but very hard to make something production-ready with them.\"\n",
    "\n",
    "\n",
    "# 사용할 GPT 모델에 맞는 토크나이저 규칙을 불러온다\n",
    "# 모델마다 토큰을 쪼개는 방식이 다르기 때문에 모델명을 반드시 지정해야 한다\n",
    "# 여기서는 gpt-4.1-mini 모델 기준 토큰 규칙을 사용한다\n",
    "encoding=tiktoken.encoding_for_model(\"gpt-4.1-mini\")\n",
    "\n",
    "# 위에서 불러온 토큰 규칙을 이용해\n",
    "# 사람이 읽는 문장(text)을 → 모델이 이해하는 숫자 토큰 리스트로 변환한다\n",
    "# 예: \"Hello\" → [15496]\n",
    "tokens=encoding.encode(text)\n",
    "\n",
    "\n",
    "# tokens는 [숫자, 숫자, 숫자, ...] 형태의 리스트\n",
    "# len(tokens)는 이 문장이 몇 개의 토큰으로 구성되어 있는지를 의미한다\n",
    "# 즉, GPT 모델이 볼 때 이 문장의 길이\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a00c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 토큰 개수를 알고 싶은 문장을 문자열(String)로 저장한다\n",
    "# 이 문장은 사람이 읽는 '한글 문장'이다\n",
    "# GPT 모델은 이 문장을 그대로 이해하지 못하고,\n",
    "# 반드시 토큰(token)이라는 작은 단위로 쪼개서 처리한다\n",
    "text = \"LLM을 사용해서 멋져 보이는 것을 만들기는 쉽지만, 프로덕션 수준으로 만들어 내기는 매우 어렵다.\"\n",
    "\n",
    "\n",
    "# 사용할 GPT 모델 이름을 지정해서,\n",
    "# 해당 모델이 사용하는 토큰 분해(Tokenizer) 규칙을 불러온다\n",
    "# 모델마다 토큰을 나누는 기준이 다르기 때문에 반드시 모델명을 정확히 써야 한다\n",
    "# 여기서는 gpt-4.1-mini 모델 기준 토큰 규칙을 사용한다\n",
    "encoding=tiktoken.encoding_for_model(\"gpt-4.1-mini\")\n",
    "\n",
    "# 위에서 불러온 토큰 규칙을 사용해서\n",
    "# 사람이 읽는 한글 문장(text)을\n",
    "# GPT 모델이 이해할 수 있는 숫자 토큰들의 리스트로 변환한다\n",
    "# 예: \"LLM\" → 하나 또는 여러 개의 숫자 토큰으로 변환될 수 있다\n",
    "tokens=encoding.encode(text)\n",
    "\n",
    "# tokens는 [숫자, 숫자, 숫자, ...] 형태의 리스트이다\n",
    "# 리스트 안의 숫자 하나가 곧 '토큰 1개'를 의미한다\n",
    "# len(tokens)는 이 리스트에 들어 있는 숫자의 개수\n",
    "# 즉, 이 한글 문장이 GPT 모델 기준으로 몇 개의 토큰을 차지하는지를 의미한다\n",
    "# 이 값은 API 비용 계산과 컨텍스트 길이 제한에 직접적인 영향을 준다\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa24ef7f",
   "metadata": {},
   "source": [
    "## 3-4 Chat Completions API를 접하는 환경 준비\n",
    "OpenAI API 키 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "227e8f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 운영체제(OS)와 관련된 기능을 사용하기 위한 파이썬 기본 라이브러리\n",
    "# 환경 변수(Environment Variable)를 읽어올 때 사용한다\n",
    "import os\n",
    "\n",
    "\n",
    "# .env 파일에 저장된 환경 변수를 불러오기 위한 라이브러리\n",
    "# API 키 같은 민감한 정보를 코드에 직접 쓰지 않게 해준다\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 현재 프로젝트 폴더에 있는 .env 파일을 읽어서\n",
    "# 그 안에 적혀 있는 값들을 \"환경 변수\"로 등록한다\n",
    "# 이 코드를 실행한 이후부터 os.getenv()로 값을 읽을 수 있다\n",
    "load_dotenv()\n",
    "\n",
    "# 운영체제에 등록된 환경 변수 중에서\n",
    "# 이름이 \"OPENAI_API_KEY\"인 값을 가져온다\n",
    "# .env 파일 안에 아래처럼 적혀 있어야 한다\n",
    "# OPENAI_API_KEY=sk-xxxxxxxxxxxx\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f08f36",
   "metadata": {},
   "source": [
    "## 3-5 Chat Completions API 사용해 보기\n",
    "OpenAI 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a83ffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (2.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f335b570",
   "metadata": {},
   "source": [
    "## Chat Completions API 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c77c647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CyAfsMNLDSa1ZIsOJbOjmgRFKuwWZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello John! How can I assist you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1768456748, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_376a7ccef1', usage=CompletionUsage(completion_tokens=10, prompt_tokens=20, total_tokens=30, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "# OpenAI API를 파이썬에서 사용하기 위한 OpenAI 클래스 불러오기\n",
    "# 이 클래스를 통해 GPT 모델과 통신할 수 있다\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# OpenAI 서버와 통신하기 위한 클라이언트 객체 생성\n",
    "# 이때 환경 변수에 저장된 OPENAI_API_KEY를 자동으로 읽어 인증한다\n",
    "client=OpenAI()\n",
    "\n",
    "\n",
    "# GPT 모델에게 대화를 보내고 응답을 받아오는 부분\n",
    "response=client.chat.completions.create(\n",
    "    # 사용할 GPT 모델 이름 지정\n",
    "    # gpt-4.1-mini는 빠르고 비용이 저렴한 GPT-4 계열 모델\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    # GPT에게 전달할 대화 내용\n",
    "    # messages는 \"대화 기록 전체\"를 리스트 형태로 전달한다\n",
    "    messages=[\n",
    "        # system 역할:\n",
    "        # GPT의 성격, 말투, 행동 규칙을 정의\n",
    "        # \"너는 친절한 도우미다\"라는 기본 설정\n",
    "        {\"role\":\"system\",\"content\":\"You are a helpful assistant.\"},\n",
    "         # user 역할:\n",
    "        # 실제 사용자가 입력한 질문 또는 메시지\n",
    "        {\"role\":\"user\",\"content\":\"Hello I'm John\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# 1️⃣ GPT 응답 객체 전체를 그대로 출력\n",
    "# -------------------------------------------\n",
    "# response는 단순한 문자열이 아니라\n",
    "# 모델 정보, 응답 내용, 토큰 사용량 등이 모두 들어 있는 객체\n",
    "# 구조를 처음 확인할 때 주로 사용\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e054f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello John! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------\n",
    "# 2️⃣ GPT가 실제로 말한 답변만 출력\n",
    "# -------------------------------------------\n",
    "# response.choices:\n",
    "#   GPT가 생성한 답변 후보들의 리스트\n",
    "# choices[0]:\n",
    "#   첫 번째(보통 유일한) 답변\n",
    "# message.content:\n",
    "#   GPT가 생성한 실제 텍스트 응답\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f17ac49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you mentioned that your name is John. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98953a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-CyAfsMNLDSa1ZIsOJbOjmgRFKuwWZ\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Hello John! How can I assist you today?\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1768456748,\n",
      "  \"model\": \"gpt-4.1-mini-2025-04-14\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_376a7ccef1\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 10,\n",
      "    \"prompt_tokens\": 20,\n",
      "    \"total_tokens\": 30,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# 3️⃣ 응답 객체를 JSON 형태로 예쁘게 출력\n",
    "# -------------------------------------------\n",
    "# model_dump_json():\n",
    "#   response 객체를 JSON 문자열로 변환\n",
    "# indent=2:\n",
    "#   들여쓰기를 적용해 사람이 읽기 쉽게 출력\n",
    "# API 응답 구조를 정확히 이해하거나\n",
    "# 로그 저장, 디버깅할 때 매우 유용\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d870c4",
   "metadata": {},
   "source": [
    "## 대화 이력을 바탕으로 한 응답 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22bf1575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-CyAft4BQV9ZsmF3A8YtukB9VS0afG\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Yes, you mentioned that your name is John. How can I help you today, John?\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1768456749,\n",
      "  \"model\": \"gpt-4.1-mini-2025-04-14\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_376a7ccef1\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 19,\n",
      "    \"prompt_tokens\": 45,\n",
      "    \"total_tokens\": 64,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# GPT 모델에게 대화 전체를 보내고,\n",
    "# 그 다음에 올 GPT의 응답을 생성하도록 요청한다\n",
    "response=client.chat.completions.create(\n",
    "\n",
    "    # 사용할 GPT 모델을 지정한다\n",
    "    # gpt-4.1-mini는 속도가 빠르고 비용이 비교적 저렴한 모델이다\n",
    "    model='gpt-4.1-mini',\n",
    "\n",
    "    # messages는 GPT에게 전달하는 \"대화 기록 전체\"이다\n",
    "    # GPT는 이 리스트를 처음부터 끝까지 읽고 다음 응답을 만든다\n",
    "    messages=[\n",
    "\n",
    "         # system 역할:\n",
    "        # GPT의 성격, 말투, 행동 규칙을 정의한다\n",
    "        # 이 대화 전체에서 GPT는 \"친절한 도우미\"로 행동한다\n",
    "        {\"role\":\"system\",\"content\":\"You are a helpful assistant\"},\n",
    "        # user 역할:\n",
    "        # 사용자가 처음으로 한 말\n",
    "        # 여기서 사용자는 자신의 이름이 John이라고 밝히고 있다\n",
    "        {\"role\":\"user\",\"content\":\"Hello! I'm John.\"},\n",
    "\n",
    "        # assistant 역할:\n",
    "        # 이전에 GPT가 했던 대답을 그대로 적어준다\n",
    "        # 이렇게 해야 GPT가 \"이전에 무엇을 말했는지\"를 알 수 있다\n",
    "        {\"role\":\"assistant\",\"content\":\"Hello John! How can I assist you today?\"},\n",
    "\n",
    "        # user 역할:\n",
    "        # 사용자가 새로 던진 질문\n",
    "        # GPT는 위의 모든 대화 내용을 보고 이 질문에 답하게 된다\n",
    "        {\"role\":\"user\",\"content\":\"Do you know my name?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# response 객체 전체를 JSON 형태로 출력한다\n",
    "# indent=2는 들여쓰기를 적용해서 사람이 읽기 쉽게 만든다\n",
    "# 이 출력에는 GPT의 답변, 모델 정보, 토큰 사용량 등이 모두 포함된다\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1827487",
   "metadata": {},
   "source": [
    "## 응답을 스트리밍으로 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e08765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'str'>\n",
      "Hello\n",
      "<class 'str'>\n",
      " John\n",
      "<class 'str'>\n",
      "!\n",
      "<class 'str'>\n",
      " How\n",
      "<class 'str'>\n",
      " can\n",
      "<class 'str'>\n",
      " I\n",
      "<class 'str'>\n",
      " assist\n",
      "<class 'str'>\n",
      " you\n",
      "<class 'str'>\n",
      " today\n",
      "<class 'str'>\n",
      "?\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# GPT 모델과 통신하기 위해 OpenAI 클라이언트를 사용한다\n",
    "# client 객체는 이미 생성되어 있다고 가정한다\n",
    "response=client.chat.completions.create(\n",
    "    # 사용할 GPT 모델을 지정한다\n",
    "    # gpt-4.1-mini는 빠르고 비용이 저렴한 GPT-4 계열 모델이다\n",
    "    model=\"gpt-4.1-mini\",\n",
    "\n",
    "     # GPT에게 전달할 대화 기록 전체\n",
    "    # GPT는 이 리스트를 처음부터 끝까지 읽고\n",
    "    # 다음에 할 말을 토큰 단위로 생성한다\n",
    "    messages=[\n",
    "\n",
    "        # system 역할:\n",
    "        # GPT의 성격과 행동 방식을 정의한다\n",
    "        # 이 대화에서 GPT는 \"친절한 도우미\"로 행동한다\n",
    "        {\"role\":\"system\",\"content\":\"You are a helpful assistant\"},\n",
    "\n",
    "        # user 역할:\n",
    "        # 사용자가 GPT에게 실제로 입력한 질문\n",
    "        {\"role\":\"user\",\"content\":\"Hello! I'm John\"}\n",
    "    ],\n",
    "\n",
    "    # stream=True 옵션:\n",
    "    # GPT가 답변을 전부 만든 뒤 한 번에 보내는 것이 아니라\n",
    "    # 토큰(글자 조각)을 생성하는 즉시\n",
    "    # 조금씩 나누어 실시간으로 보내도록 설정한다\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "\n",
    "# response는 하나의 결과 객체가 아니라\n",
    "# 여러 개의 응답 조각(chunk)을 순서대로 받을 수 있는 반복 객체이다\n",
    "# 따라서 for문으로 하나씩 꺼내서 처리한다\n",
    "for chunk in response:\n",
    "    # GPT는 여러 답변 후보를 만들 수 있기 때문에\n",
    "    # choices는 리스트 형태로 들어 있다\n",
    "    # 일반적으로 첫 번째(choice[0]) 응답만 사용한다\n",
    "    choice=chunk.choices[0]\n",
    "    # finish_reason이 None이면\n",
    "    # GPT가 아직 답변을 생성 중이라는 의미이다\n",
    "    # 답변이 끝나면 finish_reason에 \"stop\" 같은 값이 들어간다\n",
    "    if choice.finish_reason is None:\n",
    "        # delta는 이번 chunk에서 새로 추가된 내용만 담고 있다\n",
    "        # 전체 문장이 아니라, 방금 생성된 글자 조각이다\n",
    "        # 이 값을 출력하면 GPT가 타이핑하듯이 글자가 나타난다\n",
    "        print(choice.delta.content)\n",
    "        print(type(choice.delta.content))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a53a2",
   "metadata": {},
   "source": [
    "## 칼럼）Completions API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4886a3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-CyAfvufpOZKm2zO7SB5FBbJUwNUyl\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Hello John! How can I assist you today?\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1768456751,\n",
      "  \"model\": \"gpt-4.1-mini-2025-04-14\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_376a7ccef1\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 10,\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"total_tokens\": 22,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# OpenAI API를 사용하기 위해 OpenAI 클래스를 불러온다\n",
    "# 이 클래스는 GPT 모델과 통신하기 위한 핵심 도구이다\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "\n",
    "# OpenAI 서버와 통신할 수 있는 클라이언트 객체를 생성한다\n",
    "# 이때 운영체제 환경 변수에 저장된 OPENAI_API_KEY를 자동으로 읽어온다\n",
    "# (즉, API 키를 코드에 직접 쓰지 않아도 된다)\n",
    "client=OpenAI()\n",
    "\n",
    "# GPT 모델에게 메시지를 보내고,\n",
    "# 그에 대한 GPT의 응답을 받아서 response 변수에 저장한다\n",
    "response=client.chat.completions.create(\n",
    "    # 사용할 GPT 모델을 지정한다\n",
    "    # gpt-4.1-mini는 속도가 빠르고 비용이 저렴한 GPT-4 계열 모델이다\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    # GPT에게 전달할 대화 내용\n",
    "    # messages는 항상 리스트 형태이며,\n",
    "    # GPT는 이 리스트를 대화 기록으로 인식한다\n",
    "     # role이 \"user\"인 메시지:\n",
    "    # 실제 사용자가 GPT에게 입력한 문장\n",
    "    messages=[\n",
    "        {\"role\":\"user\",\"content\":\"Hello! I'm John.\"}\n",
    "    ]\n",
    ")\n",
    "# response 객체 전체를 JSON 형태로 변환하여 출력한다\n",
    "# model_dump_json()은 response 안에 들어 있는 모든 정보를 보여준다\n",
    "# indent=2는 들여쓰기를 적용해 사람이 읽기 쉽게 만든다\n",
    "# 이 출력에는 GPT의 답변, 사용된 모델, 토큰 사용량 등이 포함된다\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24a1d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-CyAfvbZkAFHxrIzRDu3uIHNQqaVW2\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Yes, you mentioned that your name is John. How can I assist you today?\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1768456751,\n",
      "  \"model\": \"gpt-4.1-mini-2025-04-14\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_376a7ccef1\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 17,\n",
      "    \"prompt_tokens\": 33,\n",
      "    \"total_tokens\": 50,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# GPT에게 전달할 \"대화 기록\"을 미리 만든다\n",
    "# messages는 리스트(list) 형태이며,\n",
    "# GPT는 이 리스트를 처음부터 끝까지 읽고\n",
    "# 다음에 할 말을 생성한다\n",
    "# -------------------------------\n",
    "messages=[\n",
    "    # user 역할:\n",
    "    # 실제 사용자가 처음으로 한 말\n",
    "    # 사용자는 자신의 이름이 John이라고 말하고 있다\n",
    "    {\"role\":\"user\",\"content\":\"Hello! I'm John.\"},\n",
    "    # assistant 역할:\n",
    "    # 이전에 GPT가 했던 대답을 그대로 넣어준다\n",
    "    # 이렇게 해야 GPT가 \"이전에 무엇을 말했는지\"를 알 수 있다\n",
    "    {\"role\":\"assistant\",\"content\":\"Nice to meet you, John!\"},\n",
    "     # user 역할:\n",
    "    # 사용자가 이어서 한 새로운 질문\n",
    "    # GPT는 위의 모든 대화 내용을 보고 이 질문에 답한다\n",
    "    {\"role\":\"user\",\"content\":\"Do you know my name?\"}\n",
    "]\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# GPT 모델에게 위에서 만든 대화 기록을 보내고\n",
    "# 그 다음에 올 GPT의 응답을 생성하도록 요청한다\n",
    "# ----------------------------------------\n",
    "response=client.chat.completions.create(\n",
    "    # 사용할 GPT 모델을 지정한다\n",
    "    # gpt-4.1-mini는 빠르고 비용이 비교적 저렴한 GPT-4 계열 모델이다\n",
    "    model='gpt-4.1-mini',\n",
    "    # 위에서 만든 messages 리스트를 그대로 전달한다\n",
    "    # 이 리스트가 곧 GPT가 참고하는 \"대화의 기억\"이다\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# GPT의 응답 전체를 JSON 형태로 출력한다\n",
    "# indent=2는 들여쓰기를 적용해\n",
    "# 사람이 읽기 쉽게 만들어 준다\n",
    "# 이 출력에는 GPT의 실제 답변, 모델 정보,\n",
    "# 토큰 사용량 등이 모두 포함된다\n",
    "# ----------------------------------------\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388df42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
