{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb5ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 운영체제(OS) 환경변수에 접근하기 위한 모듈\n",
    "# (API KEY 같은 비밀 값 읽을 때 사용)\n",
    "# ==============================\n",
    "import os\n",
    "\n",
    "# ==============================\n",
    "# .env 파일에 저장된 환경변수를\n",
    "# 파이썬 프로그램으로 불러오는 라이브러리\n",
    "# ==============================\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 현재 프로젝트 폴더에 있는 .env 파일을 읽어서\n",
    "# 환경변수로 등록\n",
    "#\n",
    "# 예)\n",
    "# .env 파일 안에\n",
    "# 가 있으면\n",
    "#\n",
    "# 이제 파이썬에서 접근 가능해짐\n",
    "# ==============================\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 환경변수에 저장된 OpenAI API KEY 값 가져오기\n",
    "#\n",
    "# os.getenv(\"변수이름\")\n",
    "# → 환경변수에서 해당 이름의 값 읽기\n",
    "#\n",
    "# 결과:\n",
    "# OPENAI_API_KEY 변수에\n",
    "\n",
    "# ==============================\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# ==============================\n",
    "# HuggingFace API 토큰도 동일한 방식으로 불러오기\n",
    "#\n",
    "# HuggingFace 모델 사용 시 필요\n",
    "# ==============================\n",
    "HUGGINGFACEHUB_API_TOKEN=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7be40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'카메라를 흥보하기 위한 좋은 문구를 추천해줘?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================\n",
    "# LangChain에서 제공하는 PromptTemplate 클래스 불러오기\n",
    "#\n",
    "# PromptTemplate:\n",
    "# → 프롬프트(질문) 틀을 만들어주는 도구\n",
    "# → 변수 넣어서 자동 문장 생성 가능\n",
    "# ==============================\n",
    "from langchain_classic import PromptTemplate\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 프롬프트 템플릿 문자열 정의\n",
    "#\n",
    "# {product} 부분은 \"변수 자리\"\n",
    "#\n",
    "# 나중에:\n",
    "# product=\"카메라\" 를 넣으면\n",
    "#\n",
    "# 결과:\n",
    "# 카메라를 흥보하기 위한 좋은 문구를 추천해줘?\n",
    "# ==============================\n",
    "template=\"{product}를 흥보하기 위한 좋은 문구를 추천해줘?\"\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# PromptTemplate 객체 생성\n",
    "#\n",
    "# input_variable:\n",
    "# → 템플릿에서 사용할 변수 이름 목록\n",
    "#\n",
    "# 현재 템플릿에 {product} 하나만 있으므로\n",
    "# [\"product\"] 하나만 등록\n",
    "#\n",
    "# template:\n",
    "# → 실제 문장 틀 전달\n",
    "# ==============================\n",
    "prompt=PromptTemplate(\n",
    "    input_variable=[\"product\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 템플릿에 실제 값 넣어서\n",
    "# 최종 프롬프트 문자열 생성\n",
    "#\n",
    "# product 자리에 \"카메라\" 대입\n",
    "#\n",
    "# 결과 문자열:\n",
    "# \"카메라를 흥보하기 위한 좋은 문구를 추천해줘?\"\n",
    "#\n",
    "# ⚠ 아직 LLM 호출 아님\n",
    "# 그냥 문자열 생성만 함\n",
    "# ==============================\n",
    "prompt.format(product=\"카메라\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4d41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21884\\164732894.py:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the `langchain-openai package and should be used instead. To use it run `pip install -U `langchain-openai` and import as `from `langchain_openai import ChatOpenAI``.\n",
      "  llm1=ChatOpenAI(temperature=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진희가 키우고 있는 동물은 강아지입니다.\n"
     ]
    }
   ],
   "source": [
    "# LangChain에서 ChatOpenAI 클래스를 불러옵니다.\n",
    "# ChatOpenAI는 \"채팅형 LLM 모델\"을 파이썬 코드에서 쉽게 쓰게 해주는 클래스입니다.\n",
    "from langchain_classic.chat_models import ChatOpenAI\n",
    "\n",
    "# ============================\n",
    "# OpenAI GPT 모델 사용 설정\n",
    "# ============================\n",
    "\n",
    "# llm1 이라는 이름의 LLM 객체 생성\n",
    "llm1=ChatOpenAI(temperature=0,  # 0이면 답변을 최대한 \"일관되고 정확하게\" 생성\n",
    "                             # (값이 클수록 창의적인 답변)\n",
    "                model='gpt-4.1-mini') # 사용할 OpenAI 모델 이름\n",
    "                                     # gpt-4.1-mini = 빠르고 저렴한 경량 GPT 모델\n",
    "# LLM에게 보낼 질문(프롬프트)\n",
    "prompt=\"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "\n",
    "# llm1.invoke() → 모델에게 질문을 보내고\n",
    "# .content → 모델이 생성한 \"텍스트 답변만\" 가져오기\n",
    "print(llm1.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce1187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# HuggingFace 모델 사용 설정\n",
    "# ============================\n",
    "\n",
    "# HuggingFace Router API를 사용해서 외부 모델을 호출하는 LLM 객체 생성\n",
    "llm2=ChatOpenAI(\n",
    "     # HuggingFace에서 제공하는 OpenAI 호환 API 주소\n",
    "    # OpenAI API 형식을 그대로 쓰면서 HuggingFace 모델을 사용 가능\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "     # HuggingFace 토큰 (로그인 인증용 비밀번호 같은 개념)\n",
    "    api_key=HUGGINGFACEHUB_API_TOKEN,\n",
    "     # 사용할 HuggingFace 모델 이름\n",
    "    model=\"HuggingFaceTB/SmolLM3-3B\",\n",
    "     # 답변 랜덤성 설정 (0 = 항상 비슷한 답변)\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# 다시 같은 질문 생성\n",
    "prompt=\"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "\n",
    "# HuggingFace 모델에게 질문 보내고 결과 출력\n",
    "print(llm2.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abbe6a8",
   "metadata": {},
   "source": [
    "**ModelLaboratory는 “교육용 실험 도구”라 보안을 전혀 고려 하지 않아서 compare로 출력하면 API_KEY가 다 출력되므로 사용하실 때는 주의!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d41ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 여러 LLM 모델을 비교하기 위한 도구 불러오기\n",
    "# ================================\n",
    "\n",
    "# ModelLaboratory는 여러 LLM에게\n",
    "# \"같은 질문\"을 동시에 보내고\n",
    "# 결과를 비교해서 보여주는 클래스입니다.\n",
    "from langchain_classic.model_laboratory import ModelLaboratory\n",
    "\n",
    "\n",
    "# ================================\n",
    "# LLM 비교 객체 생성\n",
    "# ================================\n",
    "\n",
    "# llm1, llm2 는 이전 코드에서 만든 LLM 객체\n",
    "# 예)\n",
    "# llm1 = OpenAI GPT 모델\n",
    "# llm2 = HuggingFace 모델\n",
    "\n",
    "# from_llms() 함수는\n",
    "# 여러 LLM을 리스트로 받아서\n",
    "# 비교용 객체(model_lab)를 생성합니다.\n",
    "model_lab=ModelLaboratory.from_llms([llm1,llm2])\n",
    "\n",
    "# ================================\n",
    "# 여러 모델에게 같은 질문 보내기\n",
    "# ================================\n",
    "\n",
    "# compare() 함수는\n",
    "# 리스트에 등록된 모든 모델에게\n",
    "# 같은 질문을 보내고 결과를 출력합니다.\n",
    "model_lab.compare(\"대한민국 가을은 몇월부터 몇월까지야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['두산 베어스', 'LG 트윈스', '키움 히어로즈', '한화 이글스', '삼성 라이온즈', '롯데 자이언츠', 'KIA 타이거즈', 'NC 다이노스', 'SSG 랜더스', 'KT 위즈']\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 이제부터는 OutputParser + PromptTemplate 부분\n",
    "# =====================================================\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 쉼표 리스트 파서 불러오기\n",
    "# ================================\n",
    "\n",
    "# CommaSeparatedListOutputParser는\n",
    "# LLM이 출력한\n",
    "# \"A, B, C\" 형태의 문자열을\n",
    "# [\"A\", \"B\", \"C\"] 형태의 파이썬 리스트로 바꿔줍니다.\n",
    "from langchain_classic.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "# ================================\n",
    "# 프롬프트 템플릿 도구 불러오기\n",
    "# ================================\n",
    "\n",
    "# PromptTemplate은\n",
    "# \"질문 틀\"을 만들어서\n",
    "# 변수를 끼워 넣을 수 있게 해줍니다.\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "\n",
    "# ================================\n",
    "# ChatGPT 모델 클래스 불러오기\n",
    "# ================================\n",
    "\n",
    "# OpenAI Chat 모델을 파이썬에서 쓰기 위한 클래스\n",
    "from langchain_classic.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "# ================================\n",
    "# GPT 모델 생성\n",
    "# ================================\n",
    "llm=ChatOpenAI(temperature=0, # 답변 랜덤성 (0 = 항상 비슷한 답변)\n",
    "                           # 정답형 질문에는 0이 가장 좋음\n",
    "               max_tokens=2048, # 답변 최대 길이 제한\n",
    "                                # 너무 길어지는 것 방지\n",
    "               model_name='gpt-4.1-mini',)# 사용할 GPT 모델\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Output Parser 객체 생성\n",
    "# ================================\n",
    "\n",
    "# 쉼표로 구분된 출력 결과를\n",
    "# 파이썬 리스트로 바꿀 준비\n",
    "output_parser=CommaSeparatedListOutputParser()\n",
    "\n",
    "# ================================\n",
    "# 출력 형식 지시문 생성\n",
    "# ================================\n",
    "\n",
    "# LLM에게 출력 형식을 알려주는 문장 자동 생성\n",
    "# 예:\n",
    "# \"Your response should be a list of comma separated values.\"\n",
    "format_instructions=output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "# ================================\n",
    "# PromptTemplate 생성\n",
    "# ================================\n",
    "prompt=PromptTemplate(\n",
    "    # 실제 질문 틀\n",
    "    # {subject} → 나중에 실제 질문으로 바뀜\n",
    "    # {format_instructions} → 출력 형식 지시문\n",
    "    template=\"10개의 팀을 보여줘 {subject}.\\n{format_instructions}\",\n",
    "    # 나중에 외부에서 넣을 변수 이름\n",
    "    input_variables=['subject'],\n",
    "    # 미리 고정해서 자동 삽입할 변수\n",
    "    partial_variables={\"format_instructions\":format_instructions}\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 실제 질문 내용 저장\n",
    "# ================================\n",
    "query=\"한국의의 야구팀은?\"\n",
    "\n",
    "# ================================\n",
    "# 프롬프트 완성 + LLM 호출\n",
    "# ================================\n",
    "\n",
    "# prompt.format() → 템플릿에 실제 질문 삽입\n",
    "# llm.invoke() → GPT에게 질문 전송\n",
    "# .content → 결과 텍스트만 추출\n",
    "output=llm.invoke(prompt.format(subject=query)).content\n",
    "\n",
    "\n",
    "# ================================\n",
    "# OutputParser로 결과 변환\n",
    "# ================================\n",
    "\n",
    "# GPT 출력 (문자열)을\n",
    "# 파이썬 리스트 형태로 변환\n",
    "parsed_result=output_parser.parse(output)\n",
    "\n",
    "# ================================\n",
    "# 최종 결과 출력\n",
    "# ================================\n",
    "print(parsed_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
