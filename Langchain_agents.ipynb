{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c33f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39483a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (1.2.6)\n",
      "Requirement already satisfied: openai in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (2.15.0)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (1.1.7)\n",
      "Collecting langchain-experimental\n",
      "  Downloading langchain_experimental-0.4.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (1.0.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain) (2.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: langchain-community<1.0.0,>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-experimental) (0.4.1)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.1.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (2.6.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.0.0)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.32.4.20260107-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading langchain_experimental-0.4.1-py3-none-any.whl (210 kB)\n",
      "Downloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
      "Downloading types_requests-2.32.4.20260107-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: types-requests, langchainhub, langchain-experimental\n",
      "\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   -------------------------- ------------- 2/3 [langchain-experimental]\n",
      "   ---------------------------------------- 3/3 [langchain-experimental]\n",
      "\n",
      "Successfully installed langchain-experimental-0.4.1 langchainhub-0.1.21 types-requests-2.32.4.20260107\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain openai langchain-openai langchain-experimental langchainhub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09548d8",
   "metadata": {},
   "source": [
    "## Agents 사용 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe429c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain 전체 패키지 import\n",
    "# (에이전트, 도구, 체인 등 AI 자동화 기능 제공)\n",
    "import langchain\n",
    "\n",
    "# LangChain 내부 동작 과정을 콘솔에 모두 출력하도록 설정\n",
    "# -> 에이전트의 생각, 도구 선택, 실행 과정이 전부 보임\n",
    "langchain.verbose=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a809c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: sample_data 디렉터리에 있는 파일 목록을 확인하기 위해 터미널 명령어를 실행해야 한다. Windows 환경이므로 인코딩 문제를 고려하여 명령어를 실행하고 결과를 확인하겠다.\n",
      "Action: terminal\n",
      "Action Input: chcp 65001\u001b[0mExecuting command:\n",
      " chcp 65001\n",
      "\u001b[36;1m\u001b[1;3mActive code page: 65001\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\site-packages\\langchain_community\\tools\\shell\\tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: 현재 코드 페이지를 UTF-8(65001)로 변경하여 인코딩 문제를 방지했다. 이제 sample_data 디렉터리의 파일 목록을 확인하는 명령어를 실행하겠다.\n",
      "Action: terminal\n",
      "Action Input: dir sample_data\u001b[0mExecuting command:\n",
      " dir sample_data\n",
      "\u001b[36;1m\u001b[1;3m Volume in drive C has no label.\n",
      " Volume Serial Number is 6C6F-4BFC\n",
      "\n",
      " Directory of c:\\Sesac_Workspace\\sesac_LLM_Workspace\\sample_data\n",
      "\n",
      "2026-01-21  오전 10:14    <DIR>          .\n",
      "2026-01-21  오전 10:14    <DIR>          ..\n",
      "2026-01-02  오후 03:13            23,105 diabetes.csv\n",
      "2026-01-07  오후 05:00             4,466 iris3.csv\n",
      "2025-11-21  오후 03:48            11,829 notExercise.xlsx\n",
      "2025-12-26  오전 11:33               479 scores_em.csv\n",
      "2025-12-26  오전 11:29               233 sport_test.csv\n",
      "2026-01-08  오후 01:49           361,279 wine.csv\n",
      "               6 File(s)        401,391 bytes\n",
      "               2 Dir(s)  831,043,739,648 bytes free\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: sample_data 디렉터리에는 다음과 같은 파일들이 있습니다.\n",
      "- diabetes.csv\n",
      "- iris3.csv\n",
      "- notExercise.xlsx\n",
      "- scores_em.csv\n",
      "- sport_test.csv\n",
      "- wine.csv\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# LangChain Hub (프롬프트 템플릿 저장소) 불러오기\n",
    "from langchain_classic import hub\n",
    "# Agent 관련 핵심 기능들 import\n",
    "from langchain_classic.agents import (AgentExecutor,  # 에이전트를 실제로 실행하는 실행기\n",
    "                                      create_react_agent, # ReAct(생각+행동) 방식 에이전트 생성 함수\n",
    "                                      load_tools)  # 에이전트가 사용할 도구를 불러오는 함수\n",
    "# OpenAI GPT 모델을 LangChain에서 사용하기 위한 클래스\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# =========================\n",
    "# 1. LLM (GPT 모델) 생성\n",
    "# =========================\n",
    "\n",
    "llm=ChatOpenAI(model_name='gpt-4.1-mini', # 사용할 OpenAI 모델 이름\n",
    "               temperature=0)  # 출력 랜덤성 제거 (항상 일정한 답변)\n",
    "\n",
    "# temperature=0 의미:\n",
    "# -> 자동화 작업에서는 \"창의성\"보다 \"일관성\"이 중요\n",
    "# -> 같은 입력 = 같은 결과\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. 도구(Tool) 불러오기\n",
    "# =========================\n",
    "\n",
    "tools=load_tools([\"terminal\"],  # 사용할 도구 이름: terminal (터미널 명령 실행)\n",
    "                 allow_dangerous_tools=True)  # 위험할 수 있는 도구 사용 허용\n",
    "\n",
    "\n",
    "# terminal 도구가 하는 일:\n",
    "# -> OS 명령 실행 가능\n",
    "# -> ls, dir, cat, pwd 같은 실제 터미널 명령 수행\n",
    "\n",
    "# allow_dangerous_tools=True 의미:\n",
    "# -> 파일 삭제, 시스템 명령 같은 위험 가능성도 허용\n",
    "# -> 실서비스에서는 매우 조심해야 함\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. ReAct 프롬프트 불러오기\n",
    "# =========================\n",
    "prompt=hub.pull(\"hwchase17/react\")\n",
    "\n",
    "\n",
    "\n",
    "# hub.pull 의미:\n",
    "# -> LangChain 공식 프롬프트 저장소에서 템플릿 다운로드\n",
    "\n",
    "# \"hwchase17/react\":\n",
    "# -> ReAct 에이전트용 표준 프롬프트\n",
    "# -> GPT에게 \"생각 -> 행동 -> 결과 -> 반복\" 규칙을 알려줌\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4. ReAct 에이전트 생성\n",
    "# =========================\n",
    "\n",
    "agent=create_react_agent(llm, # 사용할 GPT 모델\n",
    "                         tools,  # 사용할 도구 목록\n",
    "                         prompt)  # ReAct 행동 규칙 프롬프트\n",
    "\n",
    "# 이 한 줄에서 일어나는 일:\n",
    "\n",
    "# GPT 모델 +\n",
    "# 터미널 도구 +\n",
    "# ReAct 사고 규칙\n",
    "\n",
    "# => \"스스로 판단해서 도구를 사용할 수 있는 AI 에이전트\" 생성\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5. 에이전트 실행기 생성\n",
    "# =========================\n",
    "agent_executor=AgentExecutor(agent=agent, # 위에서 만든 에이전트\n",
    "                             tools=tools,  # 사용할 도구 목록\n",
    "                             verbose=True) # 실행 과정 로그 출력\n",
    "\n",
    "# AgentExecutor 역할:\n",
    "# -> 에이전트를 실제로 \"실행\"하는 컨트롤러\n",
    "\n",
    "# 쉽게 말하면:\n",
    "# agent = 두뇌\n",
    "# executor = 운전사\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6. 에이전트 실행\n",
    "# =========================\n",
    "result=agent_executor.invoke({\"input\":\"sample_data 디렉터리에 있는 파일 목록을 알려줘, 터미널을 사용할때 인코딩도 알아서 맞춰줘\"})\n",
    "\n",
    "\n",
    "# invoke() 의미:\n",
    "# -> 에이전트에게 실제 작업 명령\n",
    "\n",
    "# input:\n",
    "# -> 사람이 자연어로 입력한 요청\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 실행 흐름 내부 동작\n",
    "# =========================\n",
    "\n",
    "# 1) GPT가 생각\n",
    "# -> \"파일 목록 확인 필요\"\n",
    "\n",
    "# 2) 터미널 도구 선택\n",
    "# -> ls sample_data\n",
    "\n",
    "# 3) 실제 OS 명령 실행\n",
    "\n",
    "# 4) 결과 수신\n",
    "\n",
    "# 5) GPT가 결과를 자연어로 정리\n",
    "\n",
    "# result 변수에는:\n",
    "# {\n",
    "#   \"input\": 원래 질문,\n",
    "#   \"output\": 최종 답변\n",
    "# }\n",
    "# 형태로 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ea08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain에서 Tool 클래스를 불러온다\n",
    "# Tool은 \"파이썬 함수 → AI가 사용할 수 있는 도구\"로 바꿔주는 역할\n",
    "from langchain_classic.tools import Tool\n",
    "\n",
    "# ============================\n",
    "# 1. AI가 사용할 함수 정의\n",
    "# ============================\n",
    "\n",
    "def my_super_func(param):\n",
    "    # param : AI가 전달하는 입력값 (문자열 등)\n",
    "    # 지금 예제에서는 사용하지 않지만,\n",
    "    # 실제 서비스에서는 검색어, ID, 옵션 등이 들어올 수 있음\n",
    "    \n",
    "    # 항상 문자열 \"42\" 반환\n",
    "    return \"42\"\n",
    "\n",
    "# ============================\n",
    "# 2. Tool 객체 생성\n",
    "# ============================\n",
    "tools=[\n",
    "      # 파이썬 함수를 Tool 형태로 변환\n",
    "    Tool.from_function(\n",
    "        # 실제 실행될 파이썬 함수\n",
    "        func=my_super_func,\n",
    "        # AI가 인식하는 도구 이름\n",
    "        # (ReAct 에이전트가 Action 단계에서 이 이름을 사용)\n",
    "        name='The Answer',\n",
    "        # AI가 \"언제 이 도구를 써야 하는지\" 판단하는 설명\n",
    "        # 매우 중요: LLM은 description을 읽고 도구를 선택함\n",
    "        description=\"생명, 우주, 그리고 모든것에 대한 궁극적인 질문의 답\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1815dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: 이 세계의 진리를 알려주세요\n",
      "Thought: 이 세계의 진리에 대해 궁극적인 답을 얻기 위해 The Answer 도구를 사용해야겠다.\n",
      "Action: The Answer\n",
      "Action Input: 이 세계의 진리\u001b[0m\u001b[36;1m\u001b[1;3m42\u001b[0m\u001b[32;1m\u001b[1;3mThought: The observation \"42\" is a reference to the famous answer to the ultimate question of life, the universe, and everything from Douglas Adams' \"The Hitchhiker's Guide to the Galaxy.\" It symbolizes that the ultimate truth or answer is elusive or perhaps beyond simple explanation.\n",
      "Final Answer: 이 세계의 진리에 대한 궁극적인 답은 \"42\"입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '이 세계의 진리를 알려주세요', 'output': '이 세계의 진리에 대한 궁극적인 답은 \"42\"입니다.'}\n"
     ]
    }
   ],
   "source": [
    "# 현재 tools 리스트에는:\n",
    "# -> \"The Answer\" 라는 도구 하나만 등록된 상태\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 3. ReAct 에이전트 생성\n",
    "# ============================\n",
    "\n",
    "agent=create_react_agent(llm,# 사용할 GPT 모델 (예: gpt-4.1-mini)\n",
    "                         tools, # 위에서 만든 Tool 목록\n",
    "                         prompt)# ReAct 사고 규칙 프롬프트 (hwchase17/react)\n",
    "\n",
    "# 이 한 줄이 하는 일:\n",
    "\n",
    "# GPT 모델\n",
    "# + ReAct 프롬프트(생각 → 행동 → 결과 → 반복 규칙)\n",
    "# + The Answer 도구\n",
    "\n",
    "# => \"스스로 판단해서 도구를 쓸 수 있는 AI 에이전트\" 생성\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 4. 에이전트 실행기 생성\n",
    "# ============================\n",
    "agent_executor=AgentExecutor(agent=agent, # 위에서 생성한 에이전트\n",
    "                             tools=tools,# 사용할 도구 목록\n",
    "                             verbose=True)  # 내부 동작 로그 출력 (생각, 행동, 결과 확인 가능)\n",
    "\n",
    "\n",
    "# AgentExecutor 역할:\n",
    "# -> 에이전트를 실제로 실행하는 관리자\n",
    "\n",
    "# 비유:\n",
    "# agent = 두뇌\n",
    "# executor = 실행 엔진\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 5. 에이전트 실행\n",
    "# ============================\n",
    "\n",
    " # AI에게 전달할 자연어 명령\n",
    "result=agent_executor.invoke({\"input\":\"이 세계의 진리를 알려주세요\"})\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 내부에서 일어나는 실제 흐름\n",
    "# ============================\n",
    "\n",
    "# 1) GPT Thought (생각)\n",
    "# -> \"생명, 우주, 진리라는 표현이 있다\"\n",
    "# -> The Answer 도구를 사용해야겠다\n",
    "\n",
    "# 2) Action (행동)\n",
    "# -> The Answer(param=\"...\") 호출\n",
    "\n",
    "# 3) Observation (관찰)\n",
    "# -> my_super_func 실행됨\n",
    "# -> \"42\" 반환\n",
    "\n",
    "# 4) Final Answer\n",
    "# -> GPT가 \"42\"를 이용해 자연어 답변 생성\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 6. 결과 출력\n",
    "# ============================\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff4ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_28536\\436821684.py:18: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use `RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  summarize_chain=LLMChain(llm=chat,prompt=summarize_prompt)\n"
     ]
    }
   ],
   "source": [
    "# OpenAI GPT 모델을 LangChain에서 사용하기 위한 클래스\n",
    "from langchain_openai import ChatOpenAI\n",
    "# 프롬프트(질문 템플릿)를 만들기 위한 클래스\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "# \"프롬프트 + LLM\" 을 묶어서 실행하는 체인 클래스\n",
    "from langchain_classic import LLMChain\n",
    "\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 1️⃣ 요약용 프롬프트 템플릿 만들기\n",
    "# ================================\n",
    "\n",
    "# GPT에게 줄 지시문(프롬프트)\n",
    "# {input} 자리에 실제 텍스트가 들어가게 됨\n",
    "summarize_template=\"\"\"\n",
    "아래의 글을 결론만 한마디로 요약해주세요.\n",
    "\n",
    "{input}\n",
    "\"\"\"\n",
    "# PromptTemplate 객체 생성\n",
    "# → 나중에 input 변수에 값을 넣으면 자동으로 프롬프트 완성됨\n",
    "summarize_prompt=PromptTemplate(\n",
    "    input_variables=['input'], # 사용할 변수 이름\n",
    "    template=summarize_template, # 위에서 만든 프롬프트 문자열\n",
    ")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 2️⃣ GPT 모델 객체 생성\n",
    "# ================================\n",
    "chat=ChatOpenAI(model_name=\"gpt-4.1-mini\", # 사용할 OpenAI 모델\n",
    "                temperature=0) # 0이면 랜덤성 최소 (항상 안정적인 출력)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 3️⃣ LLMChain 생성\n",
    "# ================================\n",
    "\n",
    "# LLMChain = \"프롬프트 + GPT 모델\" 묶음\n",
    "# → 이 체인을 실행하면 GPT가 프롬프트에 맞게 자동 실행됨\n",
    "summarize_chain=LLMChain(llm=chat,# 사용할 GPT 모델\n",
    "                         prompt=summarize_prompt) # 사용할 프롬프트 템플릿\n",
    "\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 4️⃣ Tool 생성 (Agent가 사용할 도구)\n",
    "# ================================\n",
    "\n",
    "tools=[\n",
    "     # summarize_chain.run 함수를 Tool로 등록\n",
    "    Tool.from_function(\n",
    "        # 실제 실행될 함수\n",
    "        # Agent가 이 Tool을 선택하면 summarize_chain.run() 실행됨\n",
    "        func=summarize_chain.run,\n",
    "        # Agent가 인식하는 도구 이름\n",
    "        name='Summarizer',\n",
    "        # Agent에게 \"이 도구가 뭐하는지\" 설명\n",
    "        description='Text summarizer'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: \n",
      "다음을 요약해 주세요.\n",
      "안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다.\n",
      "OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다.\n",
      "저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다.\n",
      "제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다.\n",
      "하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다.\n",
      "질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\n",
      "\n",
      "Thought: 요약을 위해 주어진 텍스트의 핵심 내용을 간결하게 정리해야 한다.\n",
      "Action: Summarizer\n",
      "Action Input: 안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다. 제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다. 질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\u001b[0m\u001b[36;1m\u001b[1;3m저는 다양한 주제에 대해 도움을 드릴 수 있는 AI 언어 모델입니다.\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: 저는 OpenAI의 GPT-3.5 아키텍처 기반 AI 언어 모델 ChatGPT로, 자연어 이해와 생성에 능하며 2021년 9월까지의 정보를 바탕으로 다양한 질문에 답하고 대화를 나눌 수 있습니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '\\n다음을 요약해 주세요.\\n안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다.\\nOpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다.\\n저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다.\\n제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다.\\n하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다.\\n질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\\n', 'output': '저는 OpenAI의 GPT-3.5 아키텍처 기반 AI 언어 모델 ChatGPT로, 자연어 이해와 생성에 능하며 2021년 9월까지의 정보를 바탕으로 다양한 질문에 답하고 대화를 나눌 수 있습니다.'}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 5️⃣ ReAct Agent 생성\n",
    "# ================================\n",
    "\n",
    "# create_react_agent:\n",
    "# → LLM이 \"생각 → 도구선택 → 실행 → 결과분석\" 구조로 행동하도록 만듦\n",
    "\n",
    "agent=create_react_agent(llm, # 판단과 추론을 담당하는 LLM (보통 chat)\n",
    "                         tools,# 사용할 수 있는 도구 목록\n",
    "                         prompt)  # Agent 행동 규칙 프롬프트\n",
    "\n",
    "# ================================\n",
    "# 6️⃣ AgentExecutor 생성\n",
    "# ================================\n",
    "\n",
    "# AgentExecutor = Agent 실행기\n",
    "# 실제로 Agent를 실행시켜주는 컨트롤러 역할\n",
    "agent_executor=AgentExecutor(agent=agent,# 사용할 Agent\n",
    "                             tools=tools, # Agent가 사용할 Tool 목록\n",
    "                             verbose=True)  # 실행 과정 로그 전부 출력\n",
    "\n",
    "# ================================\n",
    "# 7️⃣ 요약할 원본 텍스트\n",
    "# ================================\n",
    "text=\"\"\"\n",
    "다음을 요약해 주세요.\n",
    "안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다.\n",
    "OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다.\n",
    "저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다.\n",
    "제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다.\n",
    "하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다.\n",
    "질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\n",
    "\"\"\"\n",
    "\n",
    "# ================================\n",
    "# 8️⃣ Agent 실행\n",
    "# ================================\n",
    "\n",
    "# invoke() 실행 과정:\n",
    "# 1. Agent가 input 텍스트 읽음\n",
    "# 2. \"요약 필요\" 판단\n",
    "# 3. Summarizer Tool 선택\n",
    "# 4. summarize_chain.run 실행\n",
    "# 5. GPT 요약 생성\n",
    "# 6. 결과 반환\n",
    "result=agent_executor.invoke({\"input\":text})# Agent 입력값 전달\n",
    "# ================================\n",
    "# 9️⃣ 결과 출력\n",
    "# ================================\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0defaf13",
   "metadata": {},
   "source": [
    "## Function calling을 사용하는 OpenAI Functions Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `terminal` with `{'commands': ['chcp 65001', 'dir sample_data']}`\n",
      "\n",
      "\n",
      "\u001b[0mExecuting command:\n",
      " ['chcp 65001', 'dir sample_data']\n",
      "\u001b[36;1m\u001b[1;3mParameter format not correct - 65001;dir\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\site-packages\\langchain_community\\tools\\shell\\tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `terminal` with `{'commands': ['chcp 65001', 'dir sample_data']}`\n",
      "\n",
      "\n",
      "\u001b[0mExecuting command:\n",
      " ['chcp 65001', 'dir sample_data']\n",
      "\u001b[36;1m\u001b[1;3mParameter format not correct - 65001;dir\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `terminal` with `{'commands': ['chcp 65001', 'dir sample_data']}`\n",
      "\n",
      "\n",
      "\u001b[0mExecuting command:\n",
      " ['chcp 65001', 'dir sample_data']\n",
      "\u001b[36;1m\u001b[1;3mParameter format not correct - 65001;dir\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `terminal` with `{'commands': ['chcp 65001', '&&', 'dir sample_data']}`\n",
      "\n",
      "\n",
      "\u001b[0mExecuting command:\n",
      " ['chcp 65001', '&&', 'dir sample_data']\n",
      "\u001b[36;1m\u001b[1;3mParameter format not correct - 65001;\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `terminal` with `{'commands': ['chcp 65001 && dir sample_data']}`\n",
      "\n",
      "\n",
      "\u001b[0mExecuting command:\n",
      " ['chcp 65001 && dir sample_data']\n",
      "\u001b[36;1m\u001b[1;3mActive code page: 65001\n",
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 6C6F-4BFC\n",
      "\n",
      " Directory of c:\\Sesac_Workspace\\sesac_LLM_Workspace\\sample_data\n",
      "\n",
      "2026-01-21  오전 10:14    <DIR>          .\n",
      "2026-01-21  오전 10:14    <DIR>          ..\n",
      "2026-01-02  오후 03:13            23,105 diabetes.csv\n",
      "2026-01-07  오후 05:00             4,466 iris3.csv\n",
      "2025-11-21  오후 03:48            11,829 notExercise.xlsx\n",
      "2025-12-26  오전 11:33               479 scores_em.csv\n",
      "2025-12-26  오전 11:29               233 sport_test.csv\n",
      "2026-01-08  오후 01:49           361,279 wine.csv\n",
      "               6 File(s)        401,391 bytes\n",
      "               2 Dir(s)  830,140,391,424 bytes free\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3msample_data 디렉토리에는 다음과 같은 파일들이 있습니다:\n",
      "- diabetes.csv\n",
      "- iris3.csv\n",
      "- notExercise.xlsx\n",
      "- scores_em.csv\n",
      "- sport_test.csv\n",
      "- wine.csv\n",
      "\n",
      "필요한 작업이 있으면 알려주세요!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'sample_data 디렉토리에 있는 파일 목록을 알려줘 터미널을 사용할때 인코딩도 알아서 맞춰서 해줘',\n",
       " 'output': 'sample_data 디렉토리에는 다음과 같은 파일들이 있습니다:\\n- diabetes.csv\\n- iris3.csv\\n- notExercise.xlsx\\n- scores_em.csv\\n- sport_test.csv\\n- wine.csv\\n\\n필요한 작업이 있으면 알려주세요!'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LangChain 에이전트에서 도구(tool)를 불러오는 함수\n",
    "from langchain_classic.agents import load_tools\n",
    "# Agent 실행기(관리자)와 OpenAI 함수 기반 Agent 생성 함수\n",
    "from langchain_classic.agents import AgentExecutor,create_openai_functions_agent\n",
    "# OpenAI(ChatGPT) 모델을 사용하기 위한 클래스\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 1. GPT 모델 객체 생성\n",
    "# ===============================\n",
    "\n",
    "# ChatGPT 모델을 LangChain에서 사용하기 위한 객체 생성\n",
    "# model='gpt-4.1-mini' : 사용할 OpenAI 모델 지정\n",
    "# temperature=0 : 답변의 랜덤성 제거 (항상 최대한 정확하게 동작)\n",
    "llm=ChatOpenAI(model='gpt-4.1-mini',temperature=0)\n",
    "\n",
    "# ===============================\n",
    "# 2. 사용할 Tool(도구) 불러오기\n",
    "# ===============================\n",
    "\n",
    "# terminal 도구를 로드\n",
    "# → 실제 운영체제 터미널 명령어(ls, dir 등)를 실행할 수 있음\n",
    "# allow_dangerous_tools=True\n",
    "# → rm, del 같은 위험한 명령도 허용 (주의해서 사용해야 함)\n",
    "tools=load_tools(['terminal'],allow_dangerous_tools=True)\n",
    "\n",
    "# ===============================\n",
    "# 3. Agent용 기본 프롬프트 불러오기\n",
    "# ===============================\n",
    "\n",
    "# LangChain Hub에서 Agent 전용 프롬프트 템플릿 다운로드\n",
    "# 이 프롬프트에는:\n",
    "# - 언제 도구를 써야 하는지\n",
    "# - 결과를 어떻게 정리해서 말해야 하는지\n",
    "# 규칙이 이미 정의되어 있음\n",
    "prompt=hub.pull('hwchase17/openai-functions-agent')\n",
    "\n",
    "# ===============================\n",
    "# 4. Agent 생성\n",
    "# ===============================\n",
    "\n",
    "# GPT + Tools + Prompt 를 합쳐서\n",
    "# \"도구를 사용할 줄 아는 AI Agent\" 생성\n",
    "agent=create_openai_functions_agent(llm,# GPT 두뇌\n",
    "                                    tools,# 터미널 도구\n",
    "                                    prompt)# 행동 규칙 설명서\n",
    "\n",
    "# ===============================\n",
    "# 5. Agent 실행 관리자 생성\n",
    "# ===============================\n",
    "\n",
    "# AgentExecutor는 실제 실행을 담당하는 컨트롤러\n",
    "# verbose=True :\n",
    "# → Agent가 어떤 생각을 했는지\n",
    "# → 어떤 도구를 썼는지\n",
    "# → 어떤 명령을 실행했는지\n",
    "# 전부 터미널에 출력해줌 (디버깅용)\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 6. Agent 실행 (사용자 명령 전달)\n",
    "# ===============================\n",
    "\n",
    "# invoke() 에 자연어 명령을 전달\n",
    "# Agent가 스스로 판단해서:\n",
    "# 1) 터미널이 필요한 작업인지 판단\n",
    "# 2) OS 명령 생성 (ls 또는 dir)\n",
    "# 3) 실제 실행\n",
    "# 4) 결과를 다시 정리해서 출력\n",
    "agent_executor.invoke({\"input\":\"sample_data 디렉토리에 있는 파일 목록을 알려줘 터미널을 사용할때 인코딩도 알아서 맞춰서 해줘\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f04c2fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting duckduckgo_search\n",
      "  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from duckduckgo_search) (8.1.8)\n",
      "Collecting primp>=0.15.0 (from duckduckgo_search)\n",
      "  Downloading primp-0.15.0-cp38-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: lxml>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from duckduckgo_search) (5.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=8.1.8->duckduckgo_search) (0.4.6)\n",
      "Downloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
      "Downloading primp-0.15.0-cp38-abi3-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.1/3.1 MB 21.1 MB/s eta 0:00:00\n",
      "Installing collected packages: primp, duckduckgo_search\n",
      "\n",
      "   -------------------- ------------------- 1/2 [duckduckgo_search]\n",
      "   -------------------- ------------------- 1/2 [duckduckgo_search]\n",
      "   ---------------------------------------- 2/2 [duckduckgo_search]\n",
      "\n",
      "Successfully installed duckduckgo_search-8.1.1 primp-0.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script ddgs.exe is installed in 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install duckduckgo_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92646164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ddgs\n",
      "  Downloading ddgs-9.10.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from ddgs) (8.1.8)\n",
      "Requirement already satisfied: primp>=0.15.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ddgs) (0.15.0)\n",
      "Requirement already satisfied: lxml>=4.9.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from ddgs) (5.3.0)\n",
      "Requirement already satisfied: httpx>=0.28.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
      "Requirement already satisfied: fake-useragent>=2.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ddgs) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=8.1.8->ddgs) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
      "Requirement already satisfied: brotli in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
      "Collecting h2<5,>=3 (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading h2-4.3.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.3.0)\n",
      "Downloading ddgs-9.10.0-py3-none-any.whl (40 kB)\n",
      "Downloading h2-4.3.0-py3-none-any.whl (61 kB)\n",
      "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: socksio, hyperframe, hpack, h2, ddgs\n",
      "\n",
      "   ---------------------------------------- 0/5 [socksio]\n",
      "   ---------------- ----------------------- 2/5 [hpack]\n",
      "   ---------------- ----------------------- 2/5 [hpack]\n",
      "   ------------------------ --------------- 3/5 [h2]\n",
      "   ------------------------ --------------- 3/5 [h2]\n",
      "   -------------------------------- ------- 4/5 [ddgs]\n",
      "   -------------------------------- ------- 4/5 [ddgs]\n",
      "   -------------------------------- ------- 4/5 [ddgs]\n",
      "   -------------------------------- ------- 4/5 [ddgs]\n",
      "   -------------------------------- ------- 4/5 [ddgs]\n",
      "   -------------------------------- ------- 4/5 [ddgs]\n",
      "   ---------------------------------------- 5/5 [ddgs]\n",
      "\n",
      "Successfully installed ddgs-9.10.0 h2-4.3.0 hpack-4.1.0 hyperframe-6.1.0 socksio-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script ddgs.exe is installed in 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install ddgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d99fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain 라이브러리 전체를 불러옴\n",
    "# (debug, verbose 같은 전역 옵션 설정용)\n",
    "import  langchain\n",
    "\n",
    "# =========================\n",
    "# LangChain 로그 설정\n",
    "# =========================\n",
    "\n",
    "# 내부 동작을 아주 자세하게 출력 (API 요청, 내부 처리 과정 등)\n",
    "# → 개발/디버깅 할 때 사용\n",
    "langchain.debug=True\n",
    "\n",
    "# LangChain 기본 요약 로그 출력 여부\n",
    "# → 여기서는 끔 (아래 AgentExecutor에서 verbose 따로 켬)\n",
    "langchain.verbose=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30bd528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_search` with `{'query': '서울 날씨'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m2025. 12. 28. · 28∼29일 이틀 동안 경기 북동부와 강원 내륙·산지, 대전·세종·충남은 5㎜ 안팎의 비가 예보됐다. 29일 하루 서울·인천·경기와 서해5도, 충북은 5㎜ 안팎, 전북은 5㎜ 미만, ... 3시간 전 · 아침최저기온은 -13~1도, 낮최고기온은 -6~1도를 보이겠습니다. 바다의 물결은 서해상에서 1.0~4.0m, 남해상에서 0.5~4.0m, 동해상에서 1.0~4.0m로 전해상에서 높게 일겠 ... 22시간 전 · 절기 '대한'인 오늘, 올겨울 최강 한파가 본격화했습니다. 오늘 서울 아침 기온은 영하 11.8도, 칼바람에 체감온도는 영하 18도까지 곤두박질했는데요, 한낮에도 체감 ... 2025. 9. 16. · 종로구, 서울특별시 날씨 예보 · 아침. -11°. 강수확률0% · 오후. -7°. 강수확률0% · 저녁. -12°. 강수확률0% · 밤새. -12°. 강수확률1% ... 2025. 8. 30. · 서울의 14일 간 날씨 예보 · 체감 온도: -7.4°C - 1.1°C18.7°F - 33.9°F · 평균 습도: 52% · 강수 확률: 비:61% 눈:0%.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_search` with `{'query': '부산 날씨'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mThe Weather Channel 및 Weather.com이 제공하는 오늘과 오늘 밤 부산 광역시 일기예보, 날씨 상태 및 도플러 레이더 (46700) 부산광역시 강서구 대저로 63번길 54 T. 대표전화 051-718-0200 (평일 9:00~18:00, 야간휴일은 당직실 연결) | E-mail. webmasterkma@kma.go.kr 본 홈페이지에 게시된 이메일 주소가 자동 수집되는 것을 거부하며, 이를 위반시 정보통신망법에 의해 처벌됨을 유념하시기 ... Hourly weather forecast in 부산광역시 , 부산시, 대한민국. Check current conditions in 부산광역시 , 부산시, 대한민국 with radar, hourly, and more. 다음 날 부산 : 시간별 기온 - 1월 20 18 Th 06 09 12 15 18 21 00 03 201 Th 18 Th 06 09 12 15 18 21 00 03 201 Th 25.5 ° 26 ° 28 ° 36 ° 38 ° 28 ° 26 ° 24 ° 24 ° 23.5 ° 부산 : 일출 / 일몰 - 1월 20 ... 일출 07:31 (1h 및 34m 내) 일몰 1 day ago · 부산광역시 의 날씨가 어떤지 알고 싶으신가요? korea247.kr 에서는 시간대별, 향후 며칠 또는 다음 주 동안의 날씨 예보를 확인하실 수 있습니다.\u001b[0m\u001b[32;1m\u001b[1;3m현재 서울의 날씨는 아침 최저기온이 -13도에서 1도 사이이고, 낮 최고기온은 -6도에서 1도 사이입니다. 오늘 서울은 매우 추운 날씨로, 아침 기온은 영하 11.8도이며 체감온도는 영하 18도까지 떨어질 것으로 예상됩니다.\n",
      "\n",
      "부산의 날씨 정보는 구체적인 온도는 제공되지 않았으나, 현재 부산의 일기예보와 시간별 기온, 일출 및 일몰 시간 등을 확인할 수 있습니다. 부산은 서울보다는 상대적으로 온화한 날씨일 가능성이 높습니다.\n",
      "\n",
      "더 구체적인 부산의 현재 기온이나 날씨 상태가 필요하시면 알려주세요!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Agent 관련 기능 불러오기\n",
    "# =========================\n",
    "\n",
    "# 검색, 계산기 같은 Tool(도구)을 불러오는 함수\n",
    "from langchain_classic.agents import load_tools\n",
    "# Agent 실행 관리자 + OpenAI 함수 기반 Agent 생성 함수\n",
    "from langchain_classic.agents import AgentExecutor,create_openai_functions_agent\n",
    "# OpenAI(ChatGPT) 모델을 LangChain에서 사용하기 위한 클래스\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# =========================\n",
    "# GPT 모델 생성\n",
    "# =========================\n",
    "\n",
    "# ChatGPT 모델 객체 생성\n",
    "# model='gpt-4.1-mini' → 사용할 GPT 모델\n",
    "# temperature=0 → 랜덤성 제거 (항상 최대한 정확한 답변)\n",
    "llm=ChatOpenAI(model='gpt-4.1-mini',temperature=0)\n",
    "\n",
    "# =========================\n",
    "# 검색 Tool 불러오기\n",
    "# =========================\n",
    "\n",
    "# DuckDuckGo 검색 도구 로드\n",
    "# → Agent가 인터넷 검색 가능해짐\n",
    "tools=load_tools(['ddg-search'])\n",
    "\n",
    "# =========================\n",
    "# Agent 기본 프롬프트 불러오기\n",
    "# =========================\n",
    "\n",
    "# LangChain Hub에서 공식 Agent 프롬프트 다운로드\n",
    "# → \"언제 도구를 써야 하는지\", \"어떻게 행동할지\" 규칙 포함\n",
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Agent 생성\n",
    "# =========================\n",
    "\n",
    "# GPT + 검색 Tool + 프롬프트를 합쳐서\n",
    "# \"검색할 줄 아는 AI Agent\" 생성\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "agent=create_openai_functions_agent(llm,tools,prompt)\n",
    "\n",
    "# =========================\n",
    "# Agent 실행 관리자 생성\n",
    "# =========================\n",
    "\n",
    "# AgentExecutor는 Agent를 실제로 실행하는 관리자\n",
    "# verbose=True → Agent가 생각하는 과정 출력\n",
    "agent_executor=AgentExecutor(agent=agent, # GPT 두뇌\n",
    "                             tools=tools, # 검색 도구\n",
    "                             verbose=True)  # Agent 행동 설명서\n",
    "\n",
    "# =========================\n",
    "# Agent 실행 (질문 전달)\n",
    "# =========================\n",
    "\n",
    "# 사용자 질문 전달\n",
    "# Agent가:\n",
    "# 1) 검색이 필요한지 판단\n",
    "# 2) DuckDuckGo 검색 실행\n",
    "# 3) 결과 요약\n",
    "# 4) 답변 생성\n",
    "result=agent_executor.invoke({\"input\":\"서울과 부산의 날씨를 알려줘\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d0cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 서울의 날씨는 아침 최저기온이 -13도에서 1도 사이이고, 낮 최고기온은 -6도에서 1도 사이입니다. 오늘 서울은 매우 추운 날씨로, 아침 기온은 영하 11.8도이며 체감온도는 영하 18도까지 떨어질 것으로 예상됩니다.\n",
      "\n",
      "부산의 날씨 정보는 구체적인 온도는 제공되지 않았으나, 현재 부산의 일기예보와 시간별 기온, 일출 및 일몰 시간 등을 확인할 수 있습니다. 부산은 서울보다는 상대적으로 온화한 날씨일 가능성이 높습니다.\n",
      "\n",
      "더 구체적인 부산의 현재 기온이나 날씨 상태가 필요하시면 알려주세요!\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 결과 출력\n",
    "# =========================\n",
    "\n",
    "# Agent가 최종 생성한 답변만 출력\n",
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687fb05d",
   "metadata": {},
   "source": [
    "**OpenAI API는 functions를 더 이상 사용하지 않고 tools를 사용합니다. tools API를 사용하면 모델에서 여러 함수를 한 번에 호출하도록 요청할 수 있으므로 일부 아키텍처에서 응답 시간을 줄일 수 있습니다. OpenAI 모델에는 tools agent를 사용하는 것이 좋습니다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc79da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_search` with `{'query': '서울 날씨'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m2025. 12. 28. · 28∼29일 이틀 동안 경기 북동부와 강원 내륙·산지, 대전·세종·충남은 5㎜ 안팎의 비가 예보됐다. 29일 하루 서울·인천·경기와 서해5도, 충북은 5㎜ 안팎, 전북은 5㎜ 미만, ... 3시간 전 · 아침최저기온은 -13~1도, 낮최고기온은 -6~1도를 보이겠습니다. 바다의 물결은 서해상에서 1.0~4.0m, 남해상에서 0.5~4.0m, 동해상에서 1.0~4.0m로 전해상에서 높게 일겠 ... 2025. 9. 16. · 종로구, 서울특별시 날씨 예보 · 아침. -11°. 강수확률0% · 오후. -7°. 강수확률0% · 저녁. -12°. 강수확률0% · 밤새. -12°. 강수확률1% ... 22시간 전 · 절기 '대한'인 오늘, 올겨울 최강 한파가 본격화했습니다. 오늘 서울 아침 기온은 영하 11.8도, 칼바람에 체감온도는 영하 18도까지 곤두박질했는데요, 한낮에도 체감 ... 2025. 8. 30. · 서울의 14일 간 날씨 예보 · 체감 온도: -7.4°C - 1.1°C18.7°F - 33.9°F · 평균 습도: 52% · 강수 확률: 비:61% 눈:0%.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_search` with `{'query': '부산 날씨'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m2025. 11. 10. · 내일 · 시각: 01시 · 날씨: 구름 많음 · 기온(체감온도) -4℃(-10℃) · 체감온도: -10℃ · 강수량: - · - · 강수확률: 20% · 바람: 북서풍 약간 강 4m/s ... 2025. 5. 9. · 지금은 기상할 시간! 국립밀양기상박물관에 이어 2번째로 방문한 곳? 두구두구두구!!! 부산지방기상청입니다! 기상청 국민정책기자단 이종진 기자님, ... 2025. 12. 3. · 부산 시간별날씨 ; 04시 · 4.5m/s · 습도 20% ; 05시 · 5.3m/s · 습도 20% ; 06시 · 5.7m/s · 습도 25% ; 07시 · 5.0m/s · 습도 25% ; 08시 · 5.4m/s · 습도 30% ... 6시간 전 · 낮 기온은 부산 15도, 김해 16도, 창원 17도, 사천 16도, 진주와 하동동 함안이 17도, 거창 14도 등으로 어제보다 5~9도 높겠습니다. 미세먼지 농도는 부산과 경남 모두 ... 2025. 10. 5. · 부산광역시 - 14일 기간 일기예보, 기상 정보, 웹카메라 화면, 일출 및 일몰 ... 현재 날씨; 예보; 해와 달. 부분적으로 흐림, 4.7 °C. 풍속 11 km/h. 기압, 1021 hPa.\u001b[0m\u001b[32;1m\u001b[1;3m현재 서울과 부산의 날씨 정보는 다음과 같습니다.\n",
      "\n",
      "서울: 현재 기온은 약 -13도에서 1도 사이이며, 아침 최저 기온은 -13도, 낮 최고 기온은 1도 정도입니다. 강수 확률은 낮고, 대체로 맑은 날씨가 예상됩니다.\n",
      "\n",
      "부산: 현재 기온은 약 4도에서 17도 사이이며, 아침 최저 기온은 4도, 낮 최고 기온은 17도 정도입니다. 바람은 약간 불고, 대체로 맑은 날씨가 예상됩니다.\n",
      "\n",
      "더 구체적인 시간대별 날씨나 추가 정보가 필요하시면 알려주세요.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 1. 필요한 라이브러리 가져오기\n",
    "# ==============================\n",
    "\n",
    "# Agent가 사용할 도구(tool)를 불러오는 함수\n",
    "from langchain_classic.agents import load_tools\n",
    "\n",
    "# Agent 실행기(AgentExecutor)와 OpenAI Tool 기반 Agent 생성 함수\n",
    "\n",
    "from langchain_classic.agents import AgentExecutor,create_openai_tools_agent\n",
    "\n",
    "# OpenAI Chat 모델을 사용하기 위한 클래스\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2. LLM (AI 모델) 생성\n",
    "# ==============================\n",
    "\n",
    "llm=ChatOpenAI(model='gpt-4.1-mini', # 사용할 OpenAI 모델 이름\n",
    "               temperature=0)# 답변 랜덤성 (0 = 가장 정확하고 안정적)\n",
    "\n",
    "# temperature=0 이유:\n",
    "# → Agent는 \"판단 + 도구 선택\"이 중요\n",
    "# → 창의성보다 정확성이 중요하기 때문\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. Agent가 사용할 Tool 불러오기\n",
    "# ==============================\n",
    "tools=load_tools(['ddg-search'])\n",
    "\n",
    "\n",
    "# 'ddg-search' 의미:\n",
    "# → DuckDuckGo 검색 엔진 사용\n",
    "# → Agent가 인터넷 검색을 할 수 있게 됨\n",
    "\n",
    "# tools 안에는 실제 검색 기능 객체가 들어 있음\n",
    "# 예:\n",
    "# tools = [DuckDuckGoSearchTool 객체]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. Agent 전용 Prompt 불러오기\n",
    "# ==============================\n",
    "prompt=hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "# hub.pull() :\n",
    "# → LangChain Prompt Hub에서 미리 만들어진 프롬프트 다운로드\n",
    "\n",
    "# 이 프롬프트 역할:\n",
    "# - ReAct 구조 사용 방법\n",
    "# - Tool 호출 규칙\n",
    "# - 출력 형식\n",
    "# 등을 Agent에게 알려주는 \"설명서\"\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5. Agent 생성\n",
    "# ==============================\n",
    "agent=create_openai_tools_agent(llm,  # 사용할 AI 모델\n",
    "                                tools, # 사용할 Tool 목록\n",
    "                                prompt)# Agent용 프롬프트\n",
    "\n",
    "\n",
    "# 이 한 줄에서 만들어지는 것:\n",
    "\n",
    "# LLM + Tools + Prompt\n",
    "#        ↓\n",
    "#     OpenAI Tool Calling 기반 Agent 생성\n",
    "\n",
    "# 이제 agent는:\n",
    "# - 질문 분석 가능\n",
    "# - Tool 선택 가능\n",
    "# - Function Calling(JSON 명령) 생성 가능\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 6. AgentExecutor 생성\n",
    "# ==============================\n",
    "agent_executor=AgentExecutor(agent=agent,# 위에서 만든 Agent\n",
    "                             tools=tools,# Agent가 사용할 Tool 목록\n",
    "                             verbose=True) # 실행 과정 로그 출력\n",
    "\n",
    "# AgentExecutor 역할:\n",
    "# → Agent를 실제로 실행하는 \"컨트롤러\"\n",
    "\n",
    "# verbose=True 효과:\n",
    "# 실행 중 이런 로그가 보임:\n",
    "\n",
    "# Thought: 무엇을 할지 생각\n",
    "# Action: 어떤 Tool을 쓸지 결정\n",
    "# Observation: Tool 실행 결과\n",
    "# Final Answer: 최종 답변\n",
    "\n",
    "# 즉, ReAct 과정이 전부 출력됨\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 7. Agent 실행 (질문 입력)\n",
    "# ==============================\n",
    "\n",
    "result=agent_executor.invoke({\"input\":\"서울과 부산의 날씨를 알려줘\"})\n",
    "\n",
    "\n",
    "\n",
    "# invoke() :\n",
    "# → Agent 실행 시작\n",
    "\n",
    "# input 값:\n",
    "# → Agent에게 전달할 사용자 질문\n",
    "\n",
    "# 내부 동작 자동 수행:\n",
    "\n",
    "# 1) 질문 분석\n",
    "# 2) 날씨는 인터넷 검색 필요 판단\n",
    "# 3) ddg-search Tool 선택\n",
    "# 4) 검색 실행\n",
    "# 5) 결과 분석\n",
    "# 6) 최종 답변 생성\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 8. 결과 구조 설명 (출력 예)\n",
    "# ==============================\n",
    "\n",
    "# result 구조 예시:\n",
    "\n",
    "# {\n",
    "#   \"input\": \"서울과 부산의 날씨를 알려줘\",\n",
    "#   \"output\": \"서울은 25도 맑음, 부산은 23도 흐림\",\n",
    "#   \"intermediate_steps\": [...]\n",
    "# }\n",
    "\n",
    "# 최종 답변만 출력하고 싶으면:\n",
    "\n",
    "# print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33afadbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 서울과 부산의 날씨 정보는 다음과 같습니다.\n",
      "\n",
      "서울: 현재 기온은 약 -13도에서 1도 사이이며, 아침 최저 기온은 -13도, 낮 최고 기온은 1도 정도입니다. 강수 확률은 낮고, 대체로 맑은 날씨가 예상됩니다.\n",
      "\n",
      "부산: 현재 기온은 약 4도에서 17도 사이이며, 아침 최저 기온은 4도, 낮 최고 기온은 17도 정도입니다. 바람은 약간 불고, 대체로 맑은 날씨가 예상됩니다.\n",
      "\n",
      "더 구체적인 시간대별 날씨나 추가 정보가 필요하시면 알려주세요.\n"
     ]
    }
   ],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ad000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# JSON 처리를 위한 기본 라이브러리\n",
    "# ==============================\n",
    "import json\n",
    "# → 파이썬에서 JSON 데이터를 다루기 위한 기본 모듈\n",
    "# → 지금 코드에서는 직접 사용하지 않지만\n",
    "#   결과를 파일로 저장하거나 변환할 때 자주 사용됨\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# OpenAI LLM 연결 라이브러리\n",
    "# ==============================\n",
    "from langchain_openai import ChatOpenAI\n",
    "# → OpenAI의 Chat 모델을 LangChain에서 쉽게 사용하게 해주는 클래스\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Extraction Chain 생성 함수\n",
    "# ==============================\n",
    "\n",
    "from langchain_classic.chains import create_extraction_chain\n",
    "# → 텍스트에서 원하는 정보만 \"구조화해서 추출\"하는 체인을 생성하는 함수\n",
    "# → 자연어 → JSON 변환 전용 도구\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 추출할 데이터 구조(Schema) 정의\n",
    "# ==============================\n",
    "\n",
    "\n",
    "schema={\n",
    "     # properties:\n",
    "    # → 어떤 필드를 추출할지 정의\n",
    "    \"properties\":{\n",
    "        # 사람 이름 (문자열)\n",
    "        \"person_name\":{\"type\":\"string\"},\n",
    "        # 사람 키 (정수 숫자)\n",
    "        \"person_height\":{\"type\":\"integer\"},\n",
    "        # 사람 머리 색 (문자열)\n",
    "        \"person_hair_color\":{\"type\":\"string\"},\n",
    "        # 강아지 이름 (문자열)\n",
    "        \"dog_name\":{\"type\":\"string\"},\n",
    "         # 강아지 품종 (문자열)\n",
    "        \"dog_breed\":{\"type\":'string'},\n",
    "    },\n",
    "    # required:\n",
    "    # → 반드시 포함되어야 하는 필드 지정\n",
    "    \"required\":[\"person_name\",\"person_height\"]\n",
    "}\n",
    "\n",
    "# 이 Schema의 의미:\n",
    "#\n",
    "# AI에게 이렇게 말하는 것과 같음:\n",
    "# \"텍스트에서\n",
    "#  사람 이름,\n",
    "#  키,\n",
    "#  머리색,\n",
    "#  강아지 이름,\n",
    "#  품종\n",
    "#  을 찾아서 JSON 형태로 만들어라\n",
    "#  그리고 이름과 키는 반드시 채워라\"\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 분석할 원본 텍스트\n",
    "# ==============================\n",
    "text=\"\"\"\n",
    "Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
    "Alex's dog Frosty is a labrador and likes to play hide and seek.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 이 텍스트에는 다음 정보가 섞여 있음:\n",
    "#\n",
    "# Alex 키: 5 feet\n",
    "# Claudia 키: Alex보다 1 feet 큼\n",
    "# Claudia 머리색: brunette\n",
    "# Alex 머리색: blonde\n",
    "# Alex 강아지 이름: Frosty\n",
    "# 강아지 품종: labrador\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# OpenAI Chat 모델 생성\n",
    "# ==============================\n",
    "chat=ChatOpenAI(model='gpt-4.1-mini',# 사용할 OpenAI 모델\n",
    "                temperature=0) # 랜덤성 제거 (정보 추출은 정확성이 중요)\n",
    "\n",
    "\n",
    "# temperature=0 이유:\n",
    "# → 창의적인 문장 생성이 아니라\n",
    "# → 정확한 정보 추출이 목적이기 때문\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Extraction Chain 생성\n",
    "# ==============================\n",
    "chain=create_extraction_chain(schema,chat)\n",
    "\n",
    "\n",
    "# 여기서 일어나는 일:\n",
    "#\n",
    "# schema + LLM(chat)\n",
    "#        ↓\n",
    "# \"정보 추출 전용 파이프라인\" 생성\n",
    "#\n",
    "# 이 체인은 내부적으로:\n",
    "# - 프롬프트 생성\n",
    "# - JSON Schema 적용\n",
    "# - Function Calling 구조 사용\n",
    "# 을 자동으로 처리함\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Chain 실행 (텍스트 분석 시작)\n",
    "# ==============================\n",
    "people=chain.invoke(text)\n",
    "\n",
    "\n",
    "# invoke():\n",
    "# → 체인 실행 함수\n",
    "#\n",
    "# 실행 흐름:\n",
    "#\n",
    "# 1) 텍스트를 LLM에 전달\n",
    "# 2) AI가 글을 읽음\n",
    "# 3) Schema 구조에 맞게 정보 추출\n",
    "# 4) JSON 형태 결과 반환\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 결과 형태 예시\n",
    "# ==============================\n",
    "\n",
    "# people 변수에는 보통 아래와 같은 형태가 들어 있음:\n",
    "\n",
    "# [\n",
    "#   {\n",
    "#     \"person_name\": \"Alex\",\n",
    "#     \"person_height\": 5,\n",
    "#     \"person_hair_color\": \"blonde\",\n",
    "#     \"dog_name\": \"Frosty\",\n",
    "#     \"dog_breed\": \"labrador\"\n",
    "#   }\n",
    "# ]\n",
    "\n",
    "# 리스트 형태인 이유:\n",
    "# → 여러 사람 정보가 동시에 추출될 수 있기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7462dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"input\": \"\\nAlex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\nAlex's dog Frosty is a labrador and likes to play hide and seek.\\n\",\n",
      "  \"text\": [\n",
      "    {\n",
      "      \"person_name\": \"Alex\",\n",
      "      \"person_height\": 5,\n",
      "      \"person_hair_color\": \"blonde\"\n",
      "    },\n",
      "    {\n",
      "      \"person_name\": \"Claudia\",\n",
      "      \"person_height\": 6,\n",
      "      \"person_hair_color\": \"brunette\"\n",
      "    },\n",
      "    {\n",
      "      \"person_name\": \"Frosty\",\n",
      "      \"dog_breed\": \"labrador\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# people 파이썬 객체를\n",
    "# JSON 문자열 형태로 변환한 뒤\n",
    "# 사람이 보기 좋게 들여쓰기해서\n",
    "# 콘솔에 출력한다\n",
    "print(json.dumps(people, # JSON으로 바꿀 파이썬 객체\n",
    "                 indent=2))# 들여쓰기 2칸 적용 (가독성 향상)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# OpenAI Chat 모델 사용을 위한 클래스 불러오기\n",
    "# ==============================\n",
    "from langchain_openai import ChatOpenAI\n",
    "# → OpenAI의 ChatGPT 모델을 LangChain 환경에서 사용하기 위한 클래스\n",
    "\n",
    "# ==============================\n",
    "# LLM 평가(Evaluation) 도구 불러오기\n",
    "# ==============================\n",
    "from langchain_classic.evaluation import load_evaluator\n",
    "# → LLM 답변을 자동으로 평가(채점)하는 Evaluator 로더 함수\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 평가에 사용할 LLM 생성\n",
    "# ==============================\n",
    "chat=ChatOpenAI(model='gpt-4.1-mini',# 평가를 수행할 OpenAI 모델\n",
    "                temperature=0)# 랜덤성 제거 (평가는 정확성이 중요)\n",
    "\n",
    "\n",
    "# temperature=0 이유:\n",
    "# → 평가 결과가 매번 달라지면 안 됨\n",
    "# → 항상 일관된 채점 결과를 얻기 위해 0으로 설정\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# QA(Question Answering) 평가기 생성\n",
    "# ==============================\n",
    "evaluator=load_evaluator(\"qa\",   # QA(질문-답변) 평가 타입\n",
    "                         eval_llm=chat) # 평가를 수행할 LLM 지정\n",
    "\n",
    "# \"qa\" evaluator 의미:\n",
    "# → 질문(input)\n",
    "# → 모델 답변(prediction)\n",
    "# → 정답(reference)\n",
    "# 을 비교해서\n",
    "# 답이 맞는지 판단하는 평가기\n",
    "\n",
    "# 내부적으로 LLM에게 다음과 같은 역할을 시킴:\n",
    "# \"이 답변이 정답과 의미적으로 일치하는지 판단해라\"\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 실제 평가 실행\n",
    "# ==============================\n",
    "result=evaluator.evaluate_strings(\n",
    "     # --------------------------\n",
    "    # 문제 (질문)\n",
    "    # --------------------------\n",
    "    input=\"\"\"나는 시장에 가서 사과 10개를 샀어. 사과 2개를 이웃에게 주고, 2개를 수리공에게 주었어. 그리고 사과 5개를 더 사서 1개는 내가 먹었어. 나는 몇 개의 사과를 가지고 있었니?\"\"\",\n",
    "\n",
    "    # input 의미:\n",
    "    # → 원본 문제 텍스트\n",
    "    # → 평가 기준이 되는 질문\n",
    "\n",
    "\n",
    "    # --------------------------\n",
    "    # 모델이 생성한 답변\n",
    "    # --------------------------\n",
    "    prediction=\"\"\"먼저 사과 10개로 시작했어.\n",
    "이웃에게 2개, 수리공에게 2개를 나누어 주었으므로 사과가 6개가 남았어.\n",
    "그런 다음 사과 5개를 더 사서 이제 사과가 11개가 되었어.\n",
    "마지막으로 사과 1개를 먹었으므로 사과 10개가 남게 돼.\"\"\",\n",
    "\n",
    "    # prediction 의미:\n",
    "    # → LLM(또는 시스템)이 생성한 답변\n",
    "    # → \"학생 답안지\" 같은 역할\n",
    "\n",
    "\n",
    "    # --------------------------\n",
    "    # 실제 정답\n",
    "    # -------------------------\n",
    "    reference=\"10개\",\n",
    "     # reference 의미:\n",
    "    # → 사람이 준비한 정답 데이터\n",
    "    # → 채점 기준\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da84ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': 'CORRECT', 'value': 'CORRECT', 'score': 1}\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "# ==============================\n",
    "# 결과(result) 구조 예시\n",
    "# ==============================\n",
    "\n",
    "# result 안에는 보통 이런 정보가 들어 있음:\n",
    "\n",
    "# {\n",
    "#   \"score\": 1,\n",
    "#   \"value\": \"CORRECT\",\n",
    "#   \"reasoning\": \"The prediction correctly matches the reference answer.\"\n",
    "# }\n",
    "\n",
    "# score:\n",
    "# 1 → 정답\n",
    "# 0 → 오답\n",
    "\n",
    "# value:\n",
    "# \"CORRECT\" 또는 \"INCORRECT\"\n",
    "\n",
    "# reasoning:\n",
    "# 왜 맞았는지 또는 틀렸는지 LLM이 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48df024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
