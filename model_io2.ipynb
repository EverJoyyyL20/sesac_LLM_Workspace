{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "989c28c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "HUGGINGFACEHUB_API_TOKEN=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21e5716e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'카메라를 흥보하기 위한 좋은 문구를 추천해줘?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_classic import PromptTemplate\n",
    "template=\"{product}를 흥보하기 위한 좋은 문구를 추천해줘?\"\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    input_variable=[\"product\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "prompt.format(product=\"카메라\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b652528d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진희가 키우고 있는 동물 수는 1마리입니다. (강아지 1마리)\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.chat_models import ChatOpenAI\n",
    "llm1=ChatOpenAI(temperature=0,model='gpt-4.1-mini')\n",
    "\n",
    "prompt=\"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물수는?\"\n",
    "print(llm1.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d205a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking, \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\" which translates to \"Hyunhee is raising a dog. What animal is Hyunhee raising?\" \n",
      "\n",
      "First, I need to confirm the information given. The sentence clearly states that Hyunhee is raising a dog. The question is essentially asking for the same information again, just phrased differently. \n",
      "\n",
      "I should check if there's any ambiguity or if there's a trick here. Sometimes in language, the same word can have different meanings, but in this case, \"강아지\" (gaengaji) is unambiguously a dog in Korean. \n",
      "\n",
      "The user might be testing if I can recognize the direct answer from the given statement. Since the question is a repetition of the information provided, the answer is straightforward. \n",
      "\n",
      "I should make sure there's no hidden context or additional information needed. The question is purely factual, so the answer is simply \"강아지\" (dog). \n",
      "\n",
      "No need to overcomplicate. The answer is right there in the question. Just restate it.\n",
      "</think>\n",
      "\n",
      "진희가 키우고 있는 동물은 **강아지**입니다.\n"
     ]
    }
   ],
   "source": [
    "llm2 = ChatOpenAI(\n",
    "base_url=\"https://router.huggingface.co/v1\",\n",
    "api_key=HUGGINGFACEHUB_API_TOKEN,\n",
    "model=\"HuggingFaceTB/SmolLM3-3B\",\n",
    "temperature=0,\n",
    ")\n",
    "prompt = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "print(llm2.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf54017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32b5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b48b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1bd692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
