{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cf0debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7a70c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (1.2.6)\n",
      "Requirement already satisfied: openai in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (2.15.0)\n",
      "Requirement already satisfied: pypdf in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (6.6.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (0.12.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (1.13.2)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (5.2.0)\n",
      "Requirement already satisfied: tf-keras in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (2.20.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (1.0.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain) (2.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (2.1.3)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (4.57.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (2.10.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (5.29.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (2.6.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain openai pypdf tiktoken faiss-cpu sentence-transformers tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95e491ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 운영체제(OS) 관련 기능을 사용하기 위한 모듈\n",
    "# (환경변수 읽기, 파일 경로 다루기 등)\n",
    "# ==============================\n",
    "import os\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# .env 파일에 저장된 환경변수를 불러오는 함수\n",
    "# (API KEY 같은 민감 정보 관리용)\n",
    "# ==============================\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 현재 프로젝트 폴더에 있는 .env 파일을 읽어서\n",
    "# 환경변수로 등록하는 함수 실행\n",
    "# ==============================\n",
    "load_dotenv()\n",
    "\n",
    "# ==============================\n",
    "# 환경변수 중에서 \"OPENAI_API_KEY\" 값을 가져와서\n",
    "# 파이썬 변수 OPENAI_API_KEY 에 저장\n",
    "#\n",
    "# .env 파일 예시:\n",
    "# OPENAI_API_KEY=sk-xxxxxxxx\n",
    "# ==============================\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351d21ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1    The Fence \\n \\nTom Sawyer lived with his aunt because his mother and \\nfather were dead. Tom didn’t like going to school, and he \\ndidn’t like working. He liked playing and having \\nadventures. One Friday, he didn’t go to school—he went \\nto the river. \\nAunt Polly was angry. “You’re a bad boy!” she said. \\n“Tomorrow you can’t play with your friends because you \\ndidn’t go to school today. Tomorrow you’re going to work \\nfor me. You can paint the fence.” \\nSaturday morning, Tom was not happy, but he started to \\npaint the fence. His friend Jim was in the street. \\nTom asked him, “Do you want to paint?” \\nJim said, “No, I can’t. I’m going to get water.” \\nThen Ben came to Tom’s house. He watched Tom and \\nsaid, “I’m going to swim today. You can’t swim because \\nyou’re working.” \\nTom said, “This isn’t work. I like painting.” \\n“Can I paint, too?” Ben asked. \\n“No, you can’t,” Tom answered. “Aunt Polly asked me \\nbecause I’m a very good painter.” \\nBen said, “I’m a good painter, too. Please, can I paint? I \\nhave some fruit. Do you want it?” \\nOK,” Tom said. “Give me the fruit. Then you can paint.” \\nBen started to paint the fence. Later, many boys came to \\nTom’s house. They watched Ben, and they wanted to \\npaint, too. \\nTom said, “Give me some food and you can paint.” \\n \\n1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================\n",
    "# LangChain에서 제공하는 PDF 파일 로더 클래스 불러오기\n",
    "#\n",
    "# PyPDFLoader:\n",
    "# PDF 파일을 읽어서\n",
    "# 페이지별 텍스트 데이터로 변환해주는 도구\n",
    "# ==============================\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 읽을 PDF 파일 경로 지정\n",
    "#\n",
    "# \"./\" 의미:\n",
    "# 현재 파이썬 파일이 있는 폴더\n",
    "#\n",
    "# PyPDFLoader 객체 생성\n",
    "# (아직 파일을 읽지는 않고 \"읽을 준비\"만 함)\n",
    "# ==============================\n",
    "loader=PyPDFLoader(\"./The_Adventures_of_Tom_Sawyer.pdf\")\n",
    "\n",
    "# ==============================\n",
    "# 실제로 PDF 파일을 열어서\n",
    "# 페이지별 텍스트를 읽어오는 함수 실행\n",
    "#\n",
    "# 반환 결과:\n",
    "# document = Document 객체들의 리스트(list)\n",
    "#\n",
    "# 구조 예시:\n",
    "# document[0] → 1페이지\n",
    "# document[1] → 2페이지\n",
    "# document[5] → 6페이지\n",
    "# ==============================\n",
    "document=loader.load()\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# document[5]\n",
    "# → PDF의 6번째 페이지 선택 (인덱스는 0부터 시작)\n",
    "#\n",
    "# .page_content\n",
    "# → 해당 페이지의 \"텍스트 내용\"만 가져오기\n",
    "#\n",
    "# [:5000]\n",
    "# → 앞에서부터 5000글자만 잘라서 출력\n",
    "# (너무 길어서 터미널이 넘치는 것 방지용)\n",
    "# ==============================\n",
    "document[5].page_content[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7d224b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# LangChain에서 제공하는 FAISS 벡터 데이터베이스 불러오기\n",
    "#\n",
    "# FAISS:\n",
    "# Facebook AI에서 만든 고속 벡터 검색 엔진\n",
    "# 문서를 숫자 벡터로 저장하고\n",
    "# \"의미적으로 비슷한 문서\"를 빠르게 찾을 수 있음\n",
    "# ==============================\n",
    "from langchain_classic.vectorstores import FAISS\n",
    "\n",
    "# ==============================\n",
    "# OpenAI 임베딩 모델 불러오기\n",
    "#\n",
    "# Embedding:\n",
    "# 텍스트 → 숫자 벡터(의미 좌표) 로 변환하는 모델\n",
    "#\n",
    "# 예:\n",
    "# \"강아지\" → [0.012, -0.83, 0.44, ...]\n",
    "# ==============================\n",
    "from langchain_classic.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# OpenAI 임베딩 객체 생성\n",
    "#\n",
    "# 내부적으로 OpenAI Embedding API 사용\n",
    "# (환경변수 OPENAI_API_KEY 자동 사용)\n",
    "# ==============================\n",
    "embeddings=OpenAIEmbeddings()\n",
    "\n",
    "# ==============================\n",
    "# FAISS 벡터 DB 생성\n",
    "#\n",
    "# document:\n",
    "# → PDF에서 불러온 Document 객체 리스트\n",
    "#\n",
    "# embeddings:\n",
    "# → 텍스트를 벡터로 바꿀 방법\n",
    "#\n",
    "# 실행 과정:\n",
    "# 1. document 안 텍스트 추출\n",
    "# 2. 임베딩 생성\n",
    "# 3. 벡터DB에 저장\n",
    "# ==============================\n",
    "db=FAISS.from_documents(document,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7774189b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0028138665231909497, -0.020238374776143958, -0.012738939981790699, -0.016539159741274387, -0.02259930910767389, 0.028709960370719174, -0.02787668932061184, 0.0063410627904474165, -0.012025609306402632, 0.009797242220737239, -0.015478632950228687, 0.014367605193859757, 0.0067166661065529805, -0.03338132341184305, 0.0005783971135446387, 0.02805344316490442, 0.022271049573443964, -0.00504696868553582, 0.024139597397596656, -0.027093920167150287, -0.0003393052525143871, 0.0038601892483514063, 0.01402672158245221, -0.02090751699045888, -0.0051574398382186835, 0.018306701909490415, 0.02432897625038941, -0.02041513048308164, -0.004163196670105254, -0.01867283646922085, 0.0012435932560036851, -0.0012057172991806245, -0.03547712697693411, -0.0050722191681974345, 0.001227811646132516, -0.017713313471466714, 0.01108502382139875, 0.0072658670148260844, 0.009576298984048959, 0.003251017919888031, -0.0006107494545258967, 0.003241548930682266, 0.0054288840402301934, -0.0077140655267914525, 0.015579634880875147, 0.004750273535201419, -0.01220867658626785, -0.020983268904105002, -0.01912734795109758, 0.014733738822267643]\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 테스트용 질문 문장 작성\n",
    "#\n",
    "# 실제로 검색이나 질문에 사용할 텍스트\n",
    "# ==============================\n",
    "text=\"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "\n",
    "# ==============================\n",
    "# 입력 문장을 임베딩(벡터)로 변환\n",
    "#\n",
    "# embed_query():\n",
    "# → 하나의 질문 문장을 벡터로 변환할 때 사용\n",
    "#\n",
    "# 결과:\n",
    "# 리스트(list) 형태의 숫자 배열\n",
    "# ==============================\n",
    "text_embedding=embeddings.embed_query(text)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 임베딩 결과 출력\n",
    "#\n",
    "# [:50]\n",
    "# → 벡터가 너무 길어서\n",
    "# 앞의 50개 숫자만 출력\n",
    "# ==============================\n",
    "print(text_embedding[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb177719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a353c9ddd5a46d1b453719c06949912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53343b73e8834695a5e7272c52cbab08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2abfe7d660e4cbd8838ae088c0ac35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954b567e5e4548e79a7532e6f15a953e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc9116aef894f23acc54d3dd049df8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ae924324944e75a0c23c045a677721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f201fb551f441f1aba50cdc969b2c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c284035a6ac64878a5fddb56786e0ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b1429e2a4f475bab86b3ce561a86e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0368c7287cb4970b1c0c5021720236d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7831d212f25c42228630c317d4411ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.013278771191835403, 0.07225917279720306, 0.09263105690479279, -0.003979543689638376, 0.001561832963488996, -0.10306371003389359, 0.10929881781339645, 0.055662017315626144, -0.031167343258857727, -0.05020315945148468, 0.08312953263521194, -0.008924411609768867, 0.09506326168775558, -0.06980790197849274, 0.0395590178668499, -0.10899195820093155, 0.04943861812353134, 0.03736481815576553, -0.12409231066703796, -0.003315406385809183, 0.04840955510735512, -0.03108510747551918, 0.008207017555832863, 0.06326045840978622, -0.06804245710372925, -0.0102081885561347, 0.004927072208374739, -0.014940311200916767, -0.0014765590894967318, -0.006598911248147488, -0.040159497410058975, 0.0828980877995491, 0.014144640415906906, -0.011793503537774086, -0.09415137022733688, 0.002156388945877552, -0.019053105264902115, -0.03773897886276245, -0.0032710495870560408, 0.046856045722961426, -0.18111617863178253, -0.11718792468309402, 0.03504842519760132, -0.06848115473985672, 0.06553444266319275, 0.035228561609983444, -0.04974852874875069, -0.126129612326622, -0.078459732234478, 0.004257877357304096]\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# LangChain에서 HuggingFace 임베딩 모델을 사용하기 위한 클래스 불러오기\n",
    "#\n",
    "# HuggingFaceEmbeddings:\n",
    "# HuggingFace에 공개된 문장 임베딩 모델을\n",
    "# LangChain에서 쉽게 사용할 수 있도록 만든 클래스\n",
    "# ==============================\n",
    "from langchain_classic.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 임베딩 모델 객체 생성\n",
    "#\n",
    "# model_name:\n",
    "# 사용할 HuggingFace 모델 이름 지정\n",
    "#\n",
    "# \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# → 문장 의미를 벡터로 변환하는 모델\n",
    "# → 빠르고 가볍고 성능도 좋아서 실무에서 많이 사용됨\n",
    "#\n",
    "# 실행 시:\n",
    "# 1) 처음 실행 → 모델 자동 다운로드\n",
    "# 2) 이후 실행 → 로컬 캐시에서 불러옴\n",
    "# ==============================\n",
    "embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ==============================\n",
    "# 벡터로 변환할 텍스트(문장) 준비\n",
    "#\n",
    "# 질문, 문서, 문단 등\n",
    "# 어떤 텍스트든 임베딩 가능\n",
    "# ==============================\n",
    "text = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 텍스트를 임베딩(숫자 벡터)로 변환\n",
    "#\n",
    "# embed_query():\n",
    "# → 하나의 문장을 벡터로 변환할 때 사용하는 함수\n",
    "#\n",
    "# 내부 동작:\n",
    "# 1) 문장 토큰화\n",
    "# 2) 딥러닝 모델 통과\n",
    "# 3) 의미 벡터 계산\n",
    "# 4) 리스트(list) 형태로 반환\n",
    "# ==============================\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 임베딩 결과 출력\n",
    "#\n",
    "# 임베딩 벡터는 길이가 매우 김 (약 384개 숫자)\n",
    "# 그래서 앞부분 50개 값만 출력\n",
    "#\n",
    "# [:50] 의미:\n",
    "# 리스트 앞에서부터 50개 요소만 선택\n",
    "# ==============================\n",
    "print(text_embedding[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae13e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마을 무덤에 있던 남자를 죽인 사람은 인준 조(Injun Joe)입니다.\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# LangChain에서 OpenAI의 GPT(Chat 모델)를 사용하기 위한 클래스 불러오기\n",
    "#\n",
    "# ChatOpenAI:\n",
    "# OpenAI GPT 모델을 LangChain 환경에서\n",
    "# 쉽게 사용할 수 있도록 감싸놓은(wrapper) 클래스\n",
    "# ==============================\n",
    "from langchain_classic.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# GPT 모델 객체 생성\n",
    "#\n",
    "# temperature=0\n",
    "# → 답변의 랜덤성 제거\n",
    "# → 항상 최대한 동일하고 정확한 답변 생성\n",
    "# → 문서 기반 QA(RAG)에서는 필수 설정\n",
    "#\n",
    "# model_name='gpt-4.1-mini'\n",
    "# → 빠르고 비용 효율적인 GPT 모델\n",
    "# → 검색 기반 질의응답에 충분한 성능\n",
    "# ==============================\n",
    "llm=ChatOpenAI(temperature=0,model_name='gpt-4.1-mini')\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# RetrievalQA 체인 클래스 불러오기\n",
    "#\n",
    "# RetrievalQA:\n",
    "# \"문서 검색(Retrieval)\" + \"질문 답변(QA)\"\n",
    "# 기능을 하나로 묶어 자동 처리해주는 체인\n",
    "# ==============================\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# FAISS 벡터 DB(db)를\n",
    "# 검색 전용 객체(retriever) 형태로 변환\n",
    "#\n",
    "# retriever 역할:\n",
    "# 질문 문장 →\n",
    "# 임베딩 생성 →\n",
    "# 벡터 유사도 검색 →\n",
    "# 관련 문서 반환\n",
    "# ==============================\n",
    "retriever=db.as_retriever()\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# RetrievalQA 체인 생성\n",
    "#\n",
    "# llm:\n",
    "# → 답변을 생성할 GPT 모델\n",
    "#\n",
    "# retriever:\n",
    "# → 관련 문서를 검색하는 검색기\n",
    "#\n",
    "# chain_type='stuff':\n",
    "# → 검색된 문서를 그대로 프롬프트에\n",
    "# \"한 번에 붙여서(stuff)\" GPT에게 전달하는 방식\n",
    "# → 가장 단순하고 많이 사용하는 방법\n",
    "# =========================\n",
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 사용자 질문 작성\n",
    "#\n",
    "# 이 질문은 GPT의 일반 지식이 아니라\n",
    "# PDF 문서(벡터 DB에 저장된 내용)를\n",
    "# 기반으로 답을 찾게 됨\n",
    "# ==============================\n",
    "query=\"마을 무덤에 있던 남자를 죽인 사람은 누구니?\"\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# RetrievalQA 실행\n",
    "#\n",
    "# 입력은 딕셔너리 형태:\n",
    "# {\"query\": 질문문장}\n",
    "#\n",
    "# 내부 처리 순서:\n",
    "# 1) 질문 임베딩 생성\n",
    "# 2) FAISS 벡터 DB 검색\n",
    "# 3) 관련 문서 추출\n",
    "# 4) 문서 + 질문으로 프롬프트 생성\n",
    "# 5) GPT 호출\n",
    "# 6) 답변 생성\n",
    "# ==============================\n",
    "result=qa({\"query\":query})\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 결과 출력\n",
    "#\n",
    "# result 구조:\n",
    "# {\n",
    "#   \"query\": 원본 질문,\n",
    "#   \"result\": GPT가 생성한 최종 답변,\n",
    "#   \"source_documents\": 사용된 문서 목록\n",
    "# }\n",
    "#\n",
    "# result['result']:\n",
    "# → 최종 답변 텍스트만 출력\n",
    "# ==============================\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e0f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
