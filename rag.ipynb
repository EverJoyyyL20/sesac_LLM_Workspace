{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9d4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 1. 운영체제(OS) 관련 기능 사용\n",
    "# ==============================\n",
    "import os\n",
    "# → 환경변수(API KEY 등)를 읽기 위해 사용\n",
    "\n",
    "# ==============================\n",
    "# 2. .env 파일 읽기 위한 라이브러리\n",
    "# ==============================\n",
    "from dotenv import load_dotenv\n",
    "# → .env 파일에 저장된 값을 파이썬 환경변수로 불러오는 함수\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. .env 파일 로드\n",
    "# ==============================\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "# → .env 파일 내용을 실제로 메모리에 로드\n",
    "# → override=True : 이미 같은 이름의 환경변수가 있어도 .env 값으로 덮어쓰기\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. OpenAI API KEY 가져오기\n",
    "# ==============================\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "# → 환경변수에 저장된 OPENAI_API_KEY 값을 읽어서\n",
    "# → 파이썬 변수 OPENAI_API_KEY에 저장\n",
    "# → 이후 OpenAI, LangChain 모델 사용 시 인증용으로 사용됨\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 5. 텍스트 파일 로더 불러오기\n",
    "# ==============================\n",
    "from langchain_classic.document_loaders import TextLoader\n",
    "# → 텍스트 파일(.txt)을 LangChain의 Document 형식으로 변환하는 도구\n",
    "\n",
    "# ==============================\n",
    "# 6. AI.txt 파일 불러오기\n",
    "# ==============================\n",
    "documents=TextLoader(\"AI.txt\").load()\n",
    "\n",
    "# → AI.txt 파일을 읽어서\n",
    "# → LangChain Document 객체 리스트 형태로 변환\n",
    "# → 결과 예시:\n",
    "#   [Document(page_content=\"파일 내용\", metadata={\"source\":\"AI.txt\"})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65db065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 7. 텍스트 분할기 불러오기\n",
    "# ==============================\n",
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "# → 긴 문서를 작은 조각(chunk)으로 나누는 도구\n",
    "# → 문단 → 문장 → 글자 순서로 자연스럽게 분할\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 8. 문서 분할 함수 정의\n",
    "# ==============================\n",
    "def split_docs(documents,chunk_size=1000,chunk_overlap=20):\n",
    "     # 텍스트 분할기 객체 생성\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size, # 한 chunk 당 최대 길이\n",
    "                                                 chunk_overlap=chunk_overlap)# chunk 사이 겹치는 부분\n",
    "    \n",
    "    # 실제 문서 분할 수행\n",
    "    docs=text_splitter.split_documents(documents)\n",
    "    # → 긴 문서를 여러 개의 작은 Document로 나눔\n",
    "    # → 결과 예시:\n",
    "    #   [Document(chunk1), Document(chunk2), Document(chunk3)...]\n",
    "\n",
    "    # 분할된 문서 반환\n",
    "    return docs\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 9. 함수 실행\n",
    "# ==============================\n",
    "docs=split_docs(documents)\n",
    "\n",
    "# → AI.txt에서 불러온 documents를\n",
    "# → 1000자 단위로 나누고\n",
    "# → 결과를 docs 변수에 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5723c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 1. OpenAI 임베딩 모델 불러오기\n",
    "# ==============================\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# → OpenAI에서 제공하는 \"텍스트 → 숫자 벡터\" 변환 클래스\n",
    "\n",
    "# ==============================\n",
    "# 2. 임베딩 객체 생성\n",
    "# ==============================\n",
    "embeddings=OpenAIEmbeddings(model='text-embedding-ada-002', # 텍스트를 벡터로 변환하는 OpenAI 임베딩 모델\n",
    "                            api_key=OPENAI_API_KEY)# OpenAI API 인증 키\n",
    "\n",
    "\n",
    "# → embeddings 객체 역할:\n",
    "#    문자열 → 의미 기반 숫자 벡터로 변환\n",
    "#    예: \"AI란?\" → [0.23, -0.11, 1.02, ...]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. 벡터 데이터베이스(Chroma) 불러오기\n",
    "# ==============================\n",
    "\n",
    "from langchain_classic.vectorstores import Chroma\n",
    "# → 문서 벡터를 저장하고 빠르게 검색할 수 있는 벡터 DB\n",
    "\n",
    "# ==============================\n",
    "# 4. 문서를 벡터로 변환하여 DB에 저장\n",
    "# ==============================\n",
    "db=Chroma.from_documents(docs,  # 이전 단계에서 쪼갠 문서 리스트\n",
    "                         embeddings,# 임베딩 모델 (텍스트 → 벡터 변환기)\n",
    "                         persist_directory='data')# 벡터 DB를 저장할 폴더 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efe2d788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Artificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is a field of study in computer science that develops and studies intelligent machines. Such machines may be called AIs.\n",
      "\n",
      "AI technology is widely used throughout industry, government, and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Google Assistant, Siri, and Alexa), self-driving cars (e.g., Waymo), generative and creative tools (ChatGPT and AI art), and superhuman play and analysis in strategy games (such as chess and Go).[1]\n",
      "\n",
      "Alan Turing was the first person to carry out substantial research in the field that he called Machine Intelligence.[2] Artificial intelligence was founded as an academic discipline in 1956.[3] The field went through multiple cycles of optimism[4][5] followed by disappointment and loss of funding.[6][7] Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques,[8] and after 2017 with the transformer architecture.[9] This led to the AI spring of the 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.[10]\n",
      "\n",
      "The various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics.[a] General intelligence (the ability to complete any task performable by a human) is among the field's long-term goals.[11]\n",
      "\n",
      "To solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience and other fields.[12]\n",
      "Human: AI를 한단어로 말한다면?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI를 한 단어로 표현한다면 \"지능\"이라고 할 수 있습니다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 내부에서 자동으로 일어나는 과정:\n",
    "# docs (문서 텍스트)\n",
    "#      ↓\n",
    "# embeddings (벡터 변환)\n",
    "#      ↓\n",
    "# Chroma DB 저장\n",
    "#\n",
    "# 결과:\n",
    "# db 변수에 \"검색 가능한 벡터 데이터베이스\" 생성됨\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5. GPT 모델 불러오기\n",
    "# ==============================\n",
    "\n",
    "from langchain_classic.chat_models import ChatOpenAI\n",
    "# → OpenAI GPT 모델을 LangChain에서 사용하기 위한 클래스\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 6. 사용할 GPT 모델 이름 설정\n",
    "# ==============================\n",
    "model_name='gpt-4.1-mini'\n",
    "# → 빠르고 비용 효율적인 GPT 모델\n",
    "\n",
    "# ==============================\n",
    "# 7. LLM 객체 생성 (GPT 연결)\n",
    "# ==============================\n",
    "llm=ChatOpenAI(model_name=model_name,# 사용할 GPT 모델\n",
    "               api_key=OPENAI_API_KEY)# OpenAI API 인증 키\n",
    "\n",
    "\n",
    "# → 이제 llm 객체를 통해 GPT에게 질문 가능\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 8. 질문-답변 체인 불러오기\n",
    "# ==============================\n",
    "from langchain_classic.chains.question_answering import load_qa_chain\n",
    "# → 문서 + 질문을 묶어서 GPT에게 전달하는 자동 파이프라인\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 9. QA 체인 생성\n",
    "# ==============================\n",
    "chain=load_qa_chain(llm,# 사용할 GPT 모델\n",
    "                    chain_type='stuff',# 검색된 문서를 모두 한 번에 GPT에게 전달\n",
    "                    verbose=True) # 내부 처리 과정을 콘솔에 출력 (디버깅용)\n",
    "\n",
    "# chain_type='stuff' 의미:\n",
    "# → 여러 문서를 하나로 합쳐서 GPT에게 그대로 전달\n",
    "# → 소규모 문서일 때 가장 간단한 방식\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 10. 사용자 질문 설정\n",
    "# ==============================\n",
    "query=\"AI를 한단어로 말한다면?\"\n",
    "# → 사용자가 입력한 질문\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 11. 벡터 DB에서 유사 문서 검색\n",
    "# ==============================\n",
    "matching_docs=db.similarity_search(query)\n",
    "\n",
    "# 내부 처리 과정:\n",
    "# query (\"AI란?\")\n",
    "#      ↓\n",
    "# 임베딩 변환\n",
    "#      ↓\n",
    "# DB에 저장된 문서 벡터와 비교\n",
    "#      ↓\n",
    "# 의미적으로 가장 비슷한 문서 반환\n",
    "\n",
    "# 결과:\n",
    "# matching_docs = [Document1, Document2, ...]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 12. GPT에게 문서 + 질문 전달 후 답변 생성\n",
    "# ==============================\n",
    "answer=chain.run(input_documents=matching_docs, # 검색된 관련 문서들\n",
    "                 question=query) # 실제 질문\n",
    "\n",
    "# 내부 흐름:\n",
    "# 문서 + 질문\n",
    "#      ↓\n",
    "# 프롬프트 자동 생성\n",
    "#      ↓\n",
    "# GPT 호출\n",
    "#      ↓\n",
    "# 답변 생성\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 13. 최종 결과 출력\n",
    "# ==============================\n",
    "answer\n",
    "# → AI가 생성한 최종 답변 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59d1585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
